{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9209043,"sourceType":"datasetVersion","datasetId":5568261},{"sourceId":9234376,"sourceType":"datasetVersion","datasetId":5585533},{"sourceId":9237909,"sourceType":"datasetVersion","datasetId":5587849},{"sourceId":9283562,"sourceType":"datasetVersion","datasetId":5587160},{"sourceId":9404082,"sourceType":"datasetVersion","datasetId":5709167}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport torchvision.models as models\n!pip install pytorch-msssim\nfrom pytorch_msssim import ssim as pytorch_ssim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import save_image ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-16T09:17:15.442517Z","iopub.execute_input":"2024-09-16T09:17:15.443186Z","iopub.status.idle":"2024-09-16T09:17:34.008121Z","shell.execute_reply.started":"2024-09-16T09:17:15.443150Z","shell.execute_reply":"2024-09-16T09:17:34.007244Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pytorch-msssim\n  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pytorch-msssim) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pytorch-msssim) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->pytorch-msssim) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pytorch-msssim) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pytorch-msssim) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pytorch-msssim) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pytorch-msssim) (2024.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pytorch-msssim) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pytorch-msssim) (1.3.0)\nDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\nInstalling collected packages: pytorch-msssim\nSuccessfully installed pytorch-msssim-1.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"class Inc(nn.Module):\n    def __init__(self,in_channels,filters):\n        super(Inc, self).__init__()\n        self.branch1 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1,padding=(1-1) // 2),\n            nn.LeakyReLU(),\n            nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=(3, 3), stride=(1, 1),dilation=1,padding=(3-1) // 2),\n            nn.LeakyReLU(),\n            )\n        self.branch2 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1,padding=(1-1) // 2),\n            nn.LeakyReLU(),\n            nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=(5, 5), stride=(1, 1),dilation=1,padding=(5-1) // 2),\n            nn.LeakyReLU(),\n            )\n        self.branch3 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1),\n            nn.LeakyReLU(),\n\n        )\n        self.branch4 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1),\n            nn.LeakyReLU(),\n        )\n    def forward(self,input):\n        o1 = self.branch1(input)\n        o2 = self.branch2(input)\n        o3 = self.branch3(input)\n        o4 = self.branch4(input)\n        return torch.cat([o1,o2,o3,o4],dim=1)\n\ndef swish(x):\n    return x * x.sigmoid()\n\ndef hard_sigmoid(x, inplace=False):\n    return nn.ReLU6(inplace=inplace)(x + 3) / 6\n\ndef hard_swish(x, inplace=False):\n    return x * hard_sigmoid(x, inplace)\n\nclass HardSigmoid(nn.Module):\n    def __init__(self, inplace=False):\n        super(HardSigmoid, self).__init__()\n        self.inplace = inplace\n\n    def forward(self, x):\n        return hard_sigmoid(x, inplace=self.inplace)\n\nclass HardSwish(nn.Module):\n    def __init__(self, inplace=False):\n        super(HardSwish, self).__init__()\n        self.inplace = inplace\n\n    def forward(self, x):\n        return hard_swish(x, inplace=self.inplace)\n\ndef _make_divisible(v, divisor=8, min_value=None):  ## 将通道数变成8的整数倍\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    :param v:\n    :param divisor:\n    :param min_value:\n    :return:\n    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\nclass SELayer(nn.Module):\n    def __init__(self, inp, oup, reduction=4):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n                nn.Conv2d(oup, _make_divisible(inp // reduction), 1, 1, 0,),\n                nn.ReLU(),\n                nn.Conv2d(_make_divisible(inp // reduction), oup, 1, 1, 0),\n                HardSigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\nclass DSConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DSConvBlock, self).__init__()\n        self.DW = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, groups=in_channels, padding=1, bias=False)\n        self.BN1 = nn.BatchNorm2d(in_channels)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BN2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        a = self.HS(self.BN1(self.DW(x)))\n        a = self.HS(self.BN2(self.PW(a)))\n        return a\n\nclass ConvBlock1(nn.Module):\n    def __init__(self):\n        super(ConvBlock1, self).__init__()\n        self.DW = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, groups=16, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(16)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(32)\n\n    def forward(self, x):\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass ConvBlock2(nn.Module):\n    def __init__(self):\n        super(ConvBlock2, self).__init__()\n        self.DW = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, groups=32, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(32)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(64)\n\n    def forward(self, x):\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass ConvBlock3(nn.Module):\n    def __init__(self):\n        super(ConvBlock3, self).__init__()\n        self.DW = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, groups=64, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(64)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(32)\n\n    def forward(self, x):\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass ConvBlock4(nn.Module):\n    def __init__(self):\n        super(ConvBlock4, self).__init__()\n        self.DW = nn.Conv2d(in_channels=80, out_channels=80, kernel_size=3, stride=1, groups=80, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(80)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=80, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(32)\n        self.SE = SELayer(80, 80)\n\n    def forward(self, x):\n\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.SE(a)\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass Mynet(nn.Module):\n    def __init__(self, num_layers=3):\n        super(Mynet, self).__init__()\n        self.input = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=1, stride=1, padding=0, bias=False)  ## 第一层卷积\n        self.output = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=1, stride=1, padding=0, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.block1 = ConvBlock1()\n        self.block2 = ConvBlock2()\n        self.block3 = ConvBlock3()\n        self.block4 = ConvBlock4()\n\n    def forward(self, x):\n        x = self.input(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x1)\n        # x2 = torch.cat((x, x2), 1)\n        x3 = self.block3(x2)\n        x3 = torch.cat((x, x1, x3), 1)\n        x4 = self.block4(x3)\n        out = self.output(x4)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:17:39.527863Z","iopub.execute_input":"2024-09-16T09:17:39.528316Z","iopub.status.idle":"2024-09-16T09:17:39.571753Z","shell.execute_reply.started":"2024-09-16T09:17:39.528289Z","shell.execute_reply":"2024-09-16T09:17:39.570764Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define the complete model with additional DS Conv blocks and ConvBlock4\nclass CustomModel(nn.Module):\n    def __init__(self):\n        super(CustomModel, self).__init__()\n        self.inception_block_r = Inc(in_channels=1, filters=64)\n        self.inception_block_g = Inc(in_channels=1, filters=64)\n        self.inception_block_b = Inc(in_channels=1, filters=64)\n        self.se_layer_r = SELayer(inp=256, oup=256)\n        self.se_layer_g = SELayer(inp=256, oup=256)\n        self.se_layer_b = SELayer(inp=256, oup=256)\n        self.ds_conv1 = DSConvBlock(in_channels=768, out_channels=256)\n        self.ds_conv2 = DSConvBlock(in_channels=256, out_channels=128)\n        self.ds_conv3 = DSConvBlock(in_channels=128, out_channels=16)\n        self.ds_conv4 = DSConvBlock(in_channels=16, out_channels=32)\n        self.ds_conv5 = DSConvBlock(in_channels=32, out_channels=64)\n        self.ds_conv6 = DSConvBlock(in_channels=64, out_channels=32)\n        self.conv_block4 = ConvBlock4()\n        self.final_conv = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=1, stride=1, padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # Split the input into R, G, B channels\n        r, g, b = x[:, 0:1, :, :], x[:, 1:2, :, :], x[:, 2:3, :, :]\n\n        # Process each channel independently through Inception and SE layers\n        r = self.se_layer_r(self.inception_block_r(r))\n        g = self.se_layer_g(self.inception_block_g(g))\n        b = self.se_layer_b(self.inception_block_b(b))\n\n        # Concatenate the outputs along the channel dimension (dim=1)\n        x = torch.cat([r, g, b], dim=1)  # Shape: (1, 768, 256, 256)\n\n        # Pass through the initial depthwise separable convolution blocks\n        x = self.ds_conv1(x)  # Output shape: (1, 256, 256, 256)\n        x = self.ds_conv2(x)  # Output shape: (1, 128, 256, 256)\n        x = self.ds_conv3(x)  # Output shape: (1, 16, 256, 256)\n\n        # Apply additional DS Conv blocks\n        x1 = self.ds_conv4(x)  # Output shape: (1, 32, 256, 256)\n        x2 = self.ds_conv5(x1)  # Output shape: (1, 64, 256, 256)\n        x3 = self.ds_conv6(x2)  # Output shape: (1, 32, 256, 256)\n\n        # Concatenate all outputs along the channel dimension (dim=1)\n        x = torch.cat([x, x1, x2, x3], dim=1)  # Shape: (1, 16 + 32 + 64 + 32, 256, 256) = (1, 144, 256, 256)\n        x = x[:,0:80,:,:]  # Output shape: (1, 80, 256, 256)\n        # Adjust channels before passing through ConvBlock4\n        x = self.conv_block4(x)  # Output shape: (1, 32, 256, 256)\n        # Apply final 1x1 Conv with sigmoid\n        x = self.final_conv(x)  # Output shape: (1, 3, 256, 256)\n        x = self.sigmoid(x)  # Output shape: (1, 3, 256, 256)\n        return x\n\n\n# Loss Functions\nclass SSIMLoss(nn.Module):\n    def __init__(self):\n        super(SSIMLoss, self).__init__()\n\n    def forward(self, img1, img2):\n        ssim_loss = 1 - pytorch_ssim(img1, img2, data_range=1, size_average=True)\n        return ssim_loss\n\nclass VGGLoss(nn.Module):\n    def __init__(self):\n        super(VGGLoss, self).__init__()\n        vgg = models.vgg19(pretrained=True).features\n        self.vgg = nn.Sequential(*list(vgg)[:36]).eval()\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        self.criterion = nn.MSELoss()\n\n    def forward(self, x, y):\n        x_vgg = self.vgg(x)\n        y_vgg = self.vgg(y)\n        loss = self.criterion(x_vgg, y_vgg)\n        return loss\n\nclass CombinedLoss(nn.Module):\n    def __init__(self):\n        super(CombinedLoss, self).__init__()\n        self.ssim_loss = SSIMLoss()\n        self.vgg_loss = VGGLoss()\n        self.mse_loss = nn.MSELoss()\n\n    def forward(self, output, target):\n        loss = self.mse_loss(output, target) + self.ssim_loss(output, target) + self.vgg_loss(output, target)\n        return loss\n\n# Custom Dataset class for paired images\nclass UIEDataset(Dataset):\n    def __init__(self, raw_dir, reference_dir, transform=None):\n        self.raw_dir = raw_dir\n        self.reference_dir = reference_dir\n        self.transform = transform\n        self.image_names = [img for img in os.listdir(raw_dir) if img in os.listdir(reference_dir)]\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        raw_image_path = os.path.join(self.raw_dir, self.image_names[idx])\n        reference_image_path = os.path.join(self.reference_dir, self.image_names[idx])\n\n        raw_image = Image.open(raw_image_path).convert(\"RGB\")\n        reference_image = Image.open(reference_image_path).convert(\"RGB\")\n\n        if self.transform:\n            raw_image = self.transform(raw_image)\n            reference_image = self.transform(reference_image)\n\n        return raw_image, reference_image  # Return both raw and reference images as a pair\n\n# Calculate PSNR\ndef calculate_psnr(img1, img2):\n    img1_np = img1.detach().cpu().numpy().transpose(0, 2, 3, 1)\n    img2_np = img2.detach().cpu().numpy().transpose(0, 2, 3, 1)\n    return np.mean([psnr(img1_np[i], img2_np[i], data_range=1) for i in range(img1_np.shape[0])])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:17:46.883220Z","iopub.execute_input":"2024-09-16T09:17:46.883595Z","iopub.status.idle":"2024-09-16T09:17:46.909196Z","shell.execute_reply.started":"2024-09-16T09:17:46.883563Z","shell.execute_reply":"2024-09-16T09:17:46.908327Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom PIL import Image\nimport torchvision.models as models\nfrom pytorch_msssim import ssim as pytorch_ssim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import save_image\n\nclass Inc(nn.Module):\n    def __init__(self,in_channels,filters):\n        super(Inc, self).__init__()\n        self.branch1 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1,padding=(1-1) // 2),\n            nn.LeakyReLU(),\n            nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=(3, 3), stride=(1, 1),dilation=1,padding=(3-1) // 2),\n            nn.LeakyReLU(),\n            )\n        self.branch2 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1,padding=(1-1) // 2),\n            nn.LeakyReLU(),\n            nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=(5, 5), stride=(1, 1),dilation=1,padding=(5-1) // 2),\n            nn.LeakyReLU(),\n            )\n        self.branch3 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1),\n            nn.LeakyReLU(),\n\n        )\n        self.branch4 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1),\n            nn.LeakyReLU(),\n        )\n    def forward(self,input):\n        o1 = self.branch1(input)\n        o2 = self.branch2(input)\n        o3 = self.branch3(input)\n        o4 = self.branch4(input)\n        return torch.cat([o1,o2,o3,o4],dim=1)\n\ndef swish(x):\n    return x * x.sigmoid()\n\ndef hard_sigmoid(x, inplace=False):\n    return nn.ReLU6(inplace=inplace)(x + 3) / 6\n\ndef hard_swish(x, inplace=False):\n    return x * hard_sigmoid(x, inplace)\n\nclass HardSigmoid(nn.Module):\n    def __init__(self, inplace=False):\n        super(HardSigmoid, self).__init__()\n        self.inplace = inplace\n\n    def forward(self, x):\n        return hard_sigmoid(x, inplace=self.inplace)\n\nclass HardSwish(nn.Module):\n    def __init__(self, inplace=False):\n        super(HardSwish, self).__init__()\n        self.inplace = inplace\n\n    def forward(self, x):\n        return hard_swish(x, inplace=self.inplace)\n\ndef _make_divisible(v, divisor=8, min_value=None):  ## å°†é€šé“æ•°å˜æˆ8çš„æ•´æ•°å€\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    :param v:\n    :param divisor:\n    :param min_value:\n    :return:\n    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\nclass SELayer(nn.Module):\n    def __init__(self, inp, oup, reduction=4):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n                nn.Conv2d(oup, _make_divisible(inp // reduction), 1, 1, 0,),\n                nn.ReLU(),\n                nn.Conv2d(_make_divisible(inp // reduction), oup, 1, 1, 0),\n                HardSigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\nclass DSConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DSConvBlock, self).__init__()\n        self.DW = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, groups=in_channels, padding=1, bias=False)\n        self.BN1 = nn.BatchNorm2d(in_channels)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BN2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        a = self.HS(self.BN1(self.DW(x)))\n        a = self.HS(self.BN2(self.PW(a)))\n        return a\n\nclass ConvBlock1(nn.Module):\n    def __init__(self):\n        super(ConvBlock1, self).__init__()\n        self.DW = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, groups=16, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(16)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(32)\n\n    def forward(self, x):\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass ConvBlock2(nn.Module):\n    def __init__(self):\n        super(ConvBlock2, self).__init__()\n        self.DW = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, groups=32, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(32)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(64)\n\n    def forward(self, x):\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass ConvBlock3(nn.Module):\n    def __init__(self):\n        super(ConvBlock3, self).__init__()\n        self.DW = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, groups=64, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(64)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(32)\n\n    def forward(self, x):\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass ConvBlock4(nn.Module):\n    def __init__(self):\n        super(ConvBlock4, self).__init__()\n        self.DW = nn.Conv2d(in_channels=80, out_channels=80, kernel_size=3, stride=1, groups=80, padding=1, bias=False)\n        self.BN = nn.BatchNorm2d(80)\n        self.HS = HardSwish()\n        self.PW = nn.Conv2d(in_channels=80, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False)\n        self.BNN = nn.BatchNorm2d(32)\n        self.SE = SELayer(80, 80)\n\n    def forward(self, x):\n\n        a = self.HS(self.BN(self.DW(x)))\n        a = self.SE(a)\n        a = self.HS(self.BNN(self.PW(a)))\n        return a\n\nclass Mynet(nn.Module):\n    def __init__(self, num_layers=3):\n        super(Mynet, self).__init__()\n        self.input = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=1, stride=1, padding=0, bias=False)  ## ç¬¬ä¸€å±‚å·ç§¯\n        self.output = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=1, stride=1, padding=0, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.block1 = ConvBlock1()\n        self.block2 = ConvBlock2()\n        self.block3 = ConvBlock3()\n        self.block4 = ConvBlock4()\n\n    def forward(self, x):\n        x = self.input(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x1)\n        # x2 = torch.cat((x, x2), 1)\n        x3 = self.block3(x2)\n        x3 = torch.cat((x, x1, x3), 1)\n        x4 = self.block4(x3)\n        out = self.output(x4)\n        return out\n\nfrom torchvision.models import VGG19_Weights\n# Define the complete model with additional DS Conv blocks and ConvBlock4\nclass CustomModel(nn.Module):\n    def __init__(self):\n        super(CustomModel, self).__init__()\n        self.inception_block_r = Inc(in_channels=1, filters=64)\n        self.inception_block_g = Inc(in_channels=1, filters=64)\n        self.inception_block_b = Inc(in_channels=1, filters=64)\n        self.se_layer_r = SELayer(inp=256, oup=256)\n        self.se_layer_g = SELayer(inp=256, oup=256)\n        self.se_layer_b = SELayer(inp=256, oup=256)\n        self.ds_conv1 = DSConvBlock(in_channels=768, out_channels=256)\n        self.ds_conv2 = DSConvBlock(in_channels=256, out_channels=128)\n        self.ds_conv3 = DSConvBlock(in_channels=128, out_channels=16)\n        self.ds_conv4 = DSConvBlock(in_channels=16, out_channels=32)\n        self.ds_conv5 = DSConvBlock(in_channels=32, out_channels=64)\n        self.ds_conv6 = DSConvBlock(in_channels=64, out_channels=32)\n        self.conv_block4 = ConvBlock4()\n        self.final_conv = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=1, stride=1, padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # Split the input into R, G, B channels\n        r, g, b = x[:, 0:1, :, :], x[:, 1:2, :, :], x[:, 2:3, :, :]\n\n        # Process each channel independently through Inception and SE layers\n        r = self.se_layer_r(self.inception_block_r(r))\n        g = self.se_layer_g(self.inception_block_g(g))\n        b = self.se_layer_b(self.inception_block_b(b))\n\n        # Concatenate the outputs along the channel dimension (dim=1)\n        x = torch.cat([r, g, b], dim=1)  # Shape: (1, 768, 256, 256)\n\n        # Pass through the initial depthwise separable convolution blocks\n        x = self.ds_conv1(x)  # Output shape: (1, 256, 256, 256)\n        x = self.ds_conv2(x)  # Output shape: (1, 128, 256, 256)\n        x = self.ds_conv3(x)  # Output shape: (1, 16, 256, 256)\n\n        # Apply additional DS Conv blocks\n        x1 = self.ds_conv4(x)  # Output shape: (1, 32, 256, 256)\n        x2 = self.ds_conv5(x1)  # Output shape: (1, 64, 256, 256)\n        x3 = self.ds_conv6(x2)  # Output shape: (1, 32, 256, 256)\n\n        # Concatenate all outputs along the channel dimension (dim=1)\n        x = torch.cat([x, x1, x2, x3], dim=1)  # Shape: (1, 16 + 32 + 64 + 32, 256, 256) = (1, 144, 256, 256)\n        x = x[:,0:80,:,:]  # Output shape: (1, 80, 256, 256)\n        # Adjust channels before passing through ConvBlock4\n        x = self.conv_block4(x)  # Output shape: (1, 32, 256, 256)\n        # Apply final 1x1 Conv with sigmoid\n        x = self.final_conv(x)  # Output shape: (1, 3, 256, 256)\n        x = self.sigmoid(x)  # Output shape: (1, 3, 256, 256)\n        return x\n\n\n# Loss Functions\nclass SSIMLoss(nn.Module):\n    def __init__(self):\n        super(SSIMLoss, self).__init__()\n\n    def forward(self, img1, img2):\n        ssim_loss = 1 - pytorch_ssim(img1, img2, data_range=1, size_average=True)\n        return ssim_loss\n\nclass VGGLoss(nn.Module):\n    def __init__(self):\n        super(VGGLoss, self).__init__()\n        vgg = models.vgg19(weights=VGG19_Weights.DEFAULT).features\n        self.vgg = nn.Sequential(*list(vgg)[:36]).eval()\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        self.criterion = nn.MSELoss()\n\n    def forward(self, x, y):\n        x_vgg = self.vgg(x)\n        y_vgg = self.vgg(y)\n        loss = self.criterion(x_vgg, y_vgg)\n        return loss\n\nclass CombinedLoss(nn.Module):\n    def __init__(self):\n        super(CombinedLoss, self).__init__()\n        self.ssim_loss = SSIMLoss()\n        self.vgg_loss = VGGLoss()\n        self.mse_loss = nn.MSELoss()\n\n    def forward(self, output, target):\n        loss = self.mse_loss(output, target) + self.ssim_loss(output, target) + self.vgg_loss(output, target)\n        return loss\n\n\nimport os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torchvision.utils import save_image, make_grid\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nimport pytorch_msssim\nfrom tqdm import tqdm  # Progress bar for caching\n\nclass StandardDataset(Dataset):\n    def __init__(self, raw_dir, reference_dir, transform=None):\n        self.raw_dir = raw_dir\n        self.reference_dir = reference_dir\n        self.transform = transform\n\n        self.raw_images = sorted(os.listdir(self.raw_dir))\n        self.reference_images = sorted(os.listdir(self.reference_dir))\n\n    def __len__(self):\n        return len(self.raw_images)\n\n    def __getitem__(self, idx):\n        raw_image_path = os.path.join(self.raw_dir, self.raw_images[idx])\n        reference_image_path = os.path.join(self.reference_dir, self.reference_images[idx])\n\n        raw_image = Image.open(raw_image_path).convert(\"RGB\")\n        reference_image = Image.open(reference_image_path).convert(\"RGB\")\n\n        if self.transform:\n            raw_image = self.transform(raw_image)\n            reference_image = self.transform(reference_image)\n\n        return raw_image, reference_image\n\n# Ensure calculations like PSNR are performed on the GPU\ndef calculate_psnr(outputs, targets):\n    outputs_np = outputs.detach().cpu().numpy()\n    targets_np = targets.detach().cpu().numpy()\n    psnrs = [psnr(outputs_np[i].transpose(1, 2, 0), targets_np[i].transpose(1, 2, 0), data_range=1.0)\n             for i in range(outputs.size(0))]\n    return np.mean(psnrs)\n\n# Calculate Mean Square Error (MSE) on GPU\ndef calculate_mse(outputs, targets):\n    mse_loss = nn.MSELoss().to(outputs.device)\n    mse_value = mse_loss(outputs, targets)\n    return mse_value.item()\n\ndef train_model(resume_training=True, checkpoint_path='/home4/qaiser.khan/UnderWaterImgEnh/Dataset2_model_state_dict.pth'):\n    # Hyperparameters\n    learning_rate = 0.0002\n    batch_size = 4\n    num_epochs = 100\n    start_epoch = 10  # Will update if resuming training\n\n    # Device configuration\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Model, Loss, Optimizer\n    model = CustomModel().to(device)\n    criterion = CombinedLoss().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    # Resume training from checkpoint if provided\n    if resume_training:\n        checkpoint = torch.load(checkpoint_path)\n        model.load_state_dict(checkpoint)\n        print(f\"Resuming training from saved model weights...\")\n\n    # Dataset and DataLoader\n    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n    train_dataset = StandardDataset(\n        raw_dir='/home4/qaiser.khan/UnderWaterImgEnh/ImgEnh-2/Train/Raw',\n        reference_dir='/home4/qaiser.khan/UnderWaterImgEnh/ImgEnh-2/Train/Reference',\n        transform=transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    # For plotting\n    epoch_losses = []\n    epoch_psnrs = []\n    epoch_ssims = []\n    epoch_mses = []\n\n    best_psnr = float('-inf')\n    best_mse = float('inf')\n    best_epoch = -1\n\n    print(f\"Number of images in the dataset: {len(train_dataset)}\")\n    print(\"Training started...\")\n\n    total_start_time = time.time()\n\n    for epoch in range(start_epoch, num_epochs):\n        epoch_start_time = time.time()\n\n        model.train()\n        epoch_loss = 0\n        epoch_psnr = 0\n        epoch_ssim = 0\n        epoch_mse = 0\n\n        for batch_idx, (images, targets) in enumerate(train_loader):\n            images = images.to(device)\n            targets = targets.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            epoch_psnr += calculate_psnr(outputs, targets)\n            epoch_ssim += pytorch_msssim.ssim(outputs, targets).item()\n            epoch_mse += calculate_mse(outputs, targets)\n\n        avg_loss = epoch_loss / len(train_loader)\n        avg_psnr = epoch_psnr / len(train_loader)\n        avg_ssim = epoch_ssim / len(train_loader)\n        avg_mse = epoch_mse / len(train_loader)\n\n        epoch_losses.append(avg_loss)\n        epoch_psnrs.append(avg_psnr)\n        epoch_ssims.append(avg_ssim)\n        epoch_mses.append(avg_mse)\n\n        epoch_end_time = time.time()\n        epoch_duration = epoch_end_time - epoch_start_time\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Time: {epoch_duration:.2f}s, '\n              f'Average Loss: {avg_loss:.4f}, Average PSNR: {avg_psnr:.4f}, '\n              f'Average SSIM: {avg_ssim:.4f}, Average MSE: {avg_mse:.4f}')\n\n        # Save best weights every 25 epochs\n        if (epoch + 1) % 25 == 0:\n            torch.save(model.state_dict(), f'best_model_weights_epoch_{epoch+1}.pth')\n            print(f'Best model weights saved at epoch {epoch + 1}')\n\n    total_end_time = time.time()\n    total_training_time = total_end_time - total_start_time\n\n    print(f'Total Training Time: {total_training_time:.2f}s')\n\n    # Save the final model\n    torch.save(model, 'final_model.pt')\n    print('Entire model saved!')\n    torch.save(model.state_dict(), 'final_model_state_dict.pth')\n    print('Model state dict saved!')\n\n    # Save enhanced images\n    os.makedirs('enhanced_images', exist_ok=True)\n    model.eval()\n    with torch.no_grad():\n        for i, (images, _) in enumerate(train_loader):\n            images = images.to(device)\n            outputs = model(images)\n            for j in range(images.size(0)):\n                save_image(outputs[j].cpu(), f'enhanced_images/enhanced_image_{i}_{j}.png')\n    print('All enhanced images saved!')\n\n    # Plot training metrics\n    plt.figure(figsize=(16, 4))\n\n    plt.subplot(1, 4, 1)\n    plt.plot(range(1, num_epochs + 1), epoch_losses, label='Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Loss over Epochs')\n\n    plt.subplot(1, 4, 2)\n    plt.plot(range(1, num_epochs + 1), epoch_psnrs, label='PSNR', color='g')\n    plt.xlabel('Epoch')\n    plt.ylabel('PSNR')\n    plt.title('PSNR over Epochs')\n\n    plt.subplot(1, 4, 3)\n    plt.plot(range(1, num_epochs + 1), epoch_ssims, label='SSIM', color='r')\n    plt.xlabel('Epoch')\n    plt.ylabel('SSIM')\n    plt.title('SSIM over Epochs')\n\n    plt.subplot(1, 4, 4)\n    plt.plot(range(1, num_epochs + 1), epoch_mses, label='MSE', color='b')\n    plt.xlabel('Epoch')\n    plt.ylabel('MSE')\n    plt.title('MSE over Epochs')\n\n    plt.tight_layout()\n    plt.savefig('training_metrics.png')\n    plt.show()\n\n# To resume training\ntrain_model(resume_training=True)\n\n# To start training from scratch\n#train_model()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:32:26.176566Z","iopub.status.idle":"2024-08-29T14:32:26.177067Z","shell.execute_reply.started":"2024-08-29T14:32:26.176824Z","shell.execute_reply":"2024-08-29T14:32:26.176844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use this code to start training on multi GPUs (2, 3 etc)\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nimport pytorch_msssim\n\n# updated to save all enhanced images with a size of 416 by 416\ndef calculate_psnr(outputs, targets):\n    \"\"\"\n    Calculate PSNR for each image in the batch.\n    \"\"\"\n    outputs_np = outputs.detach().cpu().numpy()\n    targets_np = targets.detach().cpu().numpy()\n    psnrs = []\n    for i in range(outputs_np.shape[0]):\n        psnr_value = psnr(outputs_np[i].transpose(1, 2, 0), targets_np[i].transpose(1, 2, 0), data_range=1.0)\n        psnrs.append(psnr_value)\n    return np.mean(psnrs)\n\n# Calculate Mean Square Error (MSE)\ndef calculate_mse(outputs, targets):\n    \"\"\"\n    Calculate MSE for each image in the batch.\n    \"\"\"\n    mse_loss = nn.MSELoss()\n    mse_value = mse_loss(outputs, targets)\n    return mse_value.item()\n\ndef train_model():\n    # Hyperparameters\n    learning_rate = 0.01\n    batch_size = 4\n    num_epochs = 2\n\n    # Device configuration\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    devices = [0, 1]  # Specify GPU IDs to use\n\n    # Model, Loss, Optimizer\n    model = CustomModel().to(device)\n    model = nn.DataParallel(model, device_ids=devices)  # Use DataParallel to split the model across multiple GPUs\n\n    criterion = CombinedLoss().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    # Dataset and DataLoader\n    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n    train_dataset = UIEDataset('/kaggle/input/imgenh-2/dataset-2/Train', transform=transform)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size * len(devices), shuffle=True)\n\n    # For plotting\n    epoch_losses = []\n    epoch_psnrs = []\n    epoch_ssims = []\n    epoch_mses = []\n\n    print(f\"Number of images in the dataset: {len(train_dataset)}\")\n    print(\"Training started...\")\n\n    for epoch in range(num_epochs):\n        model.train()\n        epoch_loss = 0\n        epoch_psnr = 0\n        epoch_ssim = 0\n        epoch_mse = 0\n        for batch_idx, (images, targets) in enumerate(train_loader):\n            images = images.to(device)\n            targets = targets.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            epoch_psnr += calculate_psnr(outputs, targets)\n            epoch_ssim += pytorch_msssim.ssim(outputs, targets).item()\n            epoch_mse += calculate_mse(outputs, targets)\n\n        avg_loss = epoch_loss / len(train_loader)\n        avg_psnr = epoch_psnr / len(train_loader)\n        avg_ssim = epoch_ssim / len(train_loader)\n        avg_mse = epoch_mse / len(train_loader)\n\n        epoch_losses.append(avg_loss)\n        epoch_psnrs.append(avg_psnr)\n        epoch_ssims.append(avg_ssim)\n        epoch_mses.append(avg_mse)\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}, Average PSNR: {avg_psnr:.4f}, Average SSIM: {avg_ssim:.4f}, Average MSE: {avg_mse:.4f}')\n\n    # Save model weights at the end of training\n    torch.save(model.state_dict(), 'UIEModel_final.pth')\n    print('Model weights saved!')\n\n    # Save all enhanced images at the end of training\n    os.makedirs('enhanced_images', exist_ok=True)  # Create a directory for enhanced images\n    model.eval()\n    with torch.no_grad():\n        for i, (images, _) in enumerate(train_loader):\n            images = images.to(device)\n            outputs = model(images)\n            for j in range(images.size(0)):\n                save_image(outputs[j].cpu(), f'enhanced_images/enhanced_image_{i}_{j}.png')\n    print('All enhanced images saved!')\n\n    # Plotting the metrics\n    plt.figure(figsize=(16, 4))\n\n    plt.subplot(1, 4, 1)\n    plt.plot(range(1, num_epochs + 1), epoch_losses, label='Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Loss vs Epoch')\n    plt.legend()\n\n    plt.subplot(1, 4, 2)\n    plt.plot(range(1, num_epochs + 1), epoch_psnrs, label='PSNR')\n    plt.xlabel('Epoch')\n    plt.ylabel('PSNR')\n    plt.title('PSNR vs Epoch')\n    plt.legend()\n\n    plt.subplot(1, 4, 3)\n    plt.plot(range(1, num_epochs + 1), epoch_ssims, label='SSIM')\n    plt.xlabel('Epoch')\n    plt.ylabel('SSIM')\n    plt.title('SSIM vs Epoch')\n    plt.legend()\n\n    plt.subplot(1, 4, 4)\n    plt.plot(range(1, num_epochs + 1), epoch_mses, label='MSE')\n    plt.xlabel('Epoch')\n    plt.ylabel('MSE')\n    plt.title('MSE vs Epoch')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.savefig('training_metrics.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    train_model()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:32:26.178554Z","iopub.status.idle":"2024-08-29T14:32:26.179007Z","shell.execute_reply.started":"2024-08-29T14:32:26.178780Z","shell.execute_reply":"2024-08-29T14:32:26.178800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Define the path to the Kaggle output directory and the directory to be zipped\noutput_dir = '/kaggle/working/'  # Path to the directory containing images\nzip_filename = '/kaggle/working/enhanced_images.zip'  # Path for the zip file\n\n# Create a zip file\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    # Walk through the directory\n    for root, dirs, files in os.walk(output_dir):\n        for file in files:\n            # Create the full file path\n            file_path = os.path.join(root, file)\n            # Add file to the zip file with relative path\n            zipf.write(file_path, os.path.relpath(file_path, os.path.join(output_dir, '..')))\n\nprint(f'Zip file created at: {zip_filename}')\n\n# Note: You can download the zip file using Kaggle's interface.\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:32:26.180076Z","iopub.status.idle":"2024-08-29T14:32:26.180545Z","shell.execute_reply.started":"2024-08-29T14:32:26.180300Z","shell.execute_reply":"2024-08-29T14:32:26.180320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our training model code \nimport os\nimport time  # Import time module to measure training time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nimport pytorch_msssim\n\n# updated to save all enhanced images with a size of 256 by 256 \ndef calculate_psnr(outputs, targets):\n    \"\"\"\n    Calculate PSNR for each image in the batch.\n    \"\"\"\n    outputs_np = outputs.detach().cpu().numpy()\n    targets_np = targets.detach().cpu().numpy()\n    psnrs = []\n    for i in range(outputs_np.shape[0]):\n        psnr_value = psnr(outputs_np[i].transpose(1, 2, 0), targets_np[i].transpose(1, 2, 0), data_range=1.0)\n        psnrs.append(psnr_value)\n    return np.mean(psnrs)\n\n# Calculate Mean Square Error (MSE)\ndef calculate_mse(outputs, targets):\n    \"\"\"\n    Calculate MSE for each image in the batch.\n    \"\"\"\n    mse_loss = nn.MSELoss()\n    mse_value = mse_loss(outputs, targets)\n    return mse_value.item()\n\ndef train_model():\n    # Hyperparameters\n    learning_rate = 0.01\n    batch_size = 4\n    num_epochs = 150\n\n    # Device configuration\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Model, Loss, Optimizer\n    model = CustomModel().to(device)\n    criterion = CombinedLoss().to(device)\n    optimizer = optim.Adamax(model.parameters(), lr=learning_rate)\n\n    # Dataset and DataLoader\n    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n    train_dataset = UIEDataset(\n    raw_dir='/kaggle/input/uieb-data/UIEB/Train/Raw',\n    reference_dir='/kaggle/input/uieb-data/UIEB/Train/Reference',\n    transform=transform\n    )\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n\n    # For plotting\n    epoch_losses = []\n    epoch_psnrs = []\n    epoch_ssims = []\n    epoch_mses = []  # Added list to store MSE values\n\n    print(f\"Number of images in the dataset: {len(train_dataset)}\")\n    print(\"Training started...\")\n\n    # Start the total training timer\n    total_start_time = time.time()\n\n    for epoch in range(num_epochs):\n        epoch_start_time = time.time()  # Start the timer for the epoch\n\n        model.train()\n        epoch_loss = 0\n        epoch_psnr = 0\n        epoch_ssim = 0\n        epoch_mse = 0  # Initialize MSE for each epoch\n        for batch_idx, (images, targets) in enumerate(train_loader):\n            images = images.to(device)\n            targets = targets.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            epoch_psnr += calculate_psnr(outputs, targets)\n            epoch_ssim += pytorch_msssim.ssim(outputs, targets).item()\n            epoch_mse += calculate_mse(outputs, targets)  # Calculate and accumulate MSE\n\n        avg_loss = epoch_loss / len(train_loader)\n        avg_psnr = epoch_psnr / len(train_loader)\n        avg_ssim = epoch_ssim / len(train_loader)\n        avg_mse = epoch_mse / len(train_loader)  # Average MSE for the epoch\n\n        epoch_losses.append(avg_loss)\n        epoch_psnrs.append(avg_psnr)\n        epoch_ssims.append(avg_ssim)\n        epoch_mses.append(avg_mse)  # Store the average MSE\n\n        epoch_end_time = time.time()  # End the timer for the epoch\n        epoch_duration = epoch_end_time - epoch_start_time\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Time: {epoch_duration:.2f}s, '\n              f'Average Loss: {avg_loss:.4f}, Average PSNR: {avg_psnr:.4f}, '\n              f'Average SSIM: {avg_ssim:.4f}, Average MSE: {avg_mse:.4f}')\n\n    # End the total training timer\n    total_end_time = time.time()\n    total_training_time = total_end_time - total_start_time\n\n    print(f'Total Training Time: {total_training_time:.2f}s')\n\n    # Save the entire model at the end of training\n    torch.save(model, 'Dataset1_model.pth')\n    print('Entire model saved!')\n\n    # Save all enhanced images at the end of training\n    os.makedirs('enhanced_images', exist_ok=True)  # Create a directory for enhanced images\n    model.eval()\n    with torch.no_grad():\n        for i, (images, _) in enumerate(train_loader):\n            images = images.to(device)\n            outputs = model(images)\n            for j in range(images.size(0)):\n                save_image(outputs[j].cpu(), f'enhanced_images/enhanced_image_{i}_{j}.png')\n    print('All enhanced images saved!')\n\n    # Plotting the metrics\n    plt.figure(figsize=(16, 4))\n\n    plt.subplot(1, 4, 1)\n    plt.plot(range(1, num_epochs + 1), epoch_losses, label='Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Loss vs Epoch')\n    plt.legend()\n\n    plt.subplot(1, 4, 2)\n    plt.plot(range(1, num_epochs + 1), epoch_psnrs, label='PSNR')\n    plt.xlabel('Epoch')\n    plt.ylabel('PSNR')\n    plt.title('PSNR vs Epoch')\n    plt.legend()\n\n    plt.subplot(1, 4, 3)\n    plt.plot(range(1, num_epochs + 1), epoch_ssims, label='SSIM')\n    plt.xlabel('Epoch')\n    plt.ylabel('SSIM')\n    plt.title('SSIM vs Epoch')\n    plt.legend()\n\n    plt.subplot(1, 4, 4)  # Added subplot for MSE\n    plt.plot(range(1, num_epochs + 1), epoch_mses, label='MSE')\n    plt.xlabel('Epoch')\n    plt.ylabel('MSE')\n    plt.title('MSE vs Epoch')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.savefig('training_metrics.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    train_model()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:32:26.183721Z","iopub.status.idle":"2024-08-29T14:32:26.184189Z","shell.execute_reply.started":"2024-08-29T14:32:26.183944Z","shell.execute_reply":"2024-08-29T14:32:26.183963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport time\n\n# Define your custom dataset class\nclass UIEDataset(torch.utils.data.Dataset):\n    def __init__(self, raw_dir, reference_dir, transform=None):\n        self.raw_dir = raw_dir\n        self.reference_dir = reference_dir\n        self.transform = transform\n        self.raw_images = sorted(os.listdir(raw_dir))\n        self.reference_images = sorted(os.listdir(reference_dir))\n\n    def __len__(self):\n        return len(self.raw_images)\n\n    def __getitem__(self, idx):\n        raw_image = Image.open(os.path.join(self.raw_dir, self.raw_images[idx])).convert('RGB')\n        reference_image = Image.open(os.path.join(self.reference_dir, self.reference_images[idx])).convert('RGB')\n        \n        if self.transform:\n            raw_image = self.transform(raw_image)\n            reference_image = self.transform(reference_image)\n        \n        return raw_image, reference_image\n\n# Define the complete model with additional DS Conv blocks and ConvBlock4\nclass CustomModel(nn.Module):\n    def __init__(self):\n        super(CustomModel, self).__init__()\n        self.inception_block_r = Inc(in_channels=1, filters=64)\n        self.inception_block_g = Inc(in_channels=1, filters=64)\n        self.inception_block_b = Inc(in_channels=1, filters=64)\n        self.se_layer_r = SELayer(inp=256, oup=256)\n        self.se_layer_g = SELayer(inp=256, oup=256)\n        self.se_layer_b = SELayer(inp=256, oup=256)\n        self.ds_conv1 = DSConvBlock(in_channels=768, out_channels=256)\n        self.ds_conv2 = DSConvBlock(in_channels=256, out_channels=128)\n        self.ds_conv3 = DSConvBlock(in_channels=128, out_channels=16)\n        self.ds_conv4 = DSConvBlock(in_channels=16, out_channels=32)\n        self.ds_conv5 = DSConvBlock(in_channels=32, out_channels=64)\n        self.ds_conv6 = DSConvBlock(in_channels=64, out_channels=32)\n        self.conv_block4 = ConvBlock4()\n        self.final_conv = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=1, stride=1, padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # Split the input into R, G, B channels\n        r, g, b = x[:, 0:1, :, :], x[:, 1:2, :, :], x[:, 2:3, :, :]\n\n        # Process each channel independently through Inception and SE layers\n        r = self.se_layer_r(self.inception_block_r(r))\n        g = self.se_layer_g(self.inception_block_g(g))\n        b = self.se_layer_b(self.inception_block_b(b))\n\n        # Concatenate the outputs along the channel dimension (dim=1)\n        x = torch.cat([r, g, b], dim=1)  # Shape: (1, 768, 256, 256)\n\n        # Pass through the initial depthwise separable convolution blocks\n        x = self.ds_conv1(x)  # Output shape: (1, 256, 256, 256)\n        x = self.ds_conv2(x)  # Output shape: (1, 128, 256, 256)\n        x = self.ds_conv3(x)  # Output shape: (1, 16, 256, 256)\n\n        # Apply additional DS Conv blocks\n        x1 = self.ds_conv4(x)  # Output shape: (1, 32, 256, 256)\n        x2 = self.ds_conv5(x1)  # Output shape: (1, 64, 256, 256)\n        x3 = self.ds_conv6(x2)  # Output shape: (1, 32, 256, 256)\n\n        # Concatenate all outputs along the channel dimension (dim=1)\n        x = torch.cat([x, x1, x2, x3], dim=1)  # Shape: (1, 16 + 32 + 64 + 32, 256, 256) = (1, 144, 256, 256)\n        x = x[:,0:80,:,:]  # Output shape: (1, 80, 256, 256)\n        # Adjust channels before passing through ConvBlock4\n        x = self.conv_block4(x)  # Output shape: (1, 32, 256, 256)\n        # Apply final 1x1 Conv with sigmoid\n        x = self.final_conv(x)  # Output shape: (1, 3, 256, 256)\n        x = self.sigmoid(x)  # Output shape: (1, 3, 256, 256)\n        return x\n\n\n# Utility function for plotting loss\ndef plot_loss(train_losses, val_losses=None, output_dir=None, batch_size=None, lr=None, optimizer_name=None):\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_losses, label='Train Loss')\n    if val_losses:\n        plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title(f'Loss over Epochs (BS={batch_size}, LR={lr}, Opt={optimizer_name})')\n    plt.grid(True)\n    plt.savefig(os.path.join(output_dir, f'loss_plot_bs{batch_size}_lr{lr}_opt{optimizer_name}.png'))\n    plt.show()\n\n# Define directories\nraw_dir = '/kaggle/input/uieb-data/UIEB/Test/Raw'\nreference_dir = '/kaggle/input/uieb-data/UIEB/Test/Reference'\noutput_dir = '/kaggle/working/'\nmodel_path = '/kaggle/input/uieb-model/UIEModel_final(1).pth'\n\n# Hyperparameter grid\nbatch_sizes = [2, 4]\nlearning_rates = [0.0002, 0.0001, 0.02,0.01]\noptimizers = {\n    'SGD': optim.SGD,\n    'Adam': optim.Adam,\n    'WSGD': optim.SGD,  # Placeholder for your WSGD implementation\n    'Adamax': optim.Adamax,\n    'Nadam': optim.NAdam\n}\n\n# Check for GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Load weights function\ndef load_weights(model, path):\n    checkpoint = torch.load(path)\n    model_state_dict = model.state_dict()\n    \n    # Check if all keys match\n    for key in checkpoint.keys():\n        if key not in model_state_dict:\n            print(f\"Skipping key: {key}\")\n    # Load only the matching keys\n    model_state_dict.update({k: v for k, v in checkpoint.items() if k in model_state_dict})\n    model.load_state_dict(model_state_dict)\n\n# Training function\ndef train_and_evaluate(batch_size, lr, optimizer_name):\n    print(f\"\\nTraining with Batch Size: {batch_size}, Learning Rate: {lr}, Optimizer: {optimizer_name}\")\n    \n    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n    dataset = UIEDataset(raw_dir, reference_dir, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    model = CustomModel().to(device)  # Move model to GPU\n    load_weights(model, model_path)\n    model.train()\n\n    criterion = nn.MSELoss()  # Use appropriate loss function\n    optimizer_class = optimizers[optimizer_name]\n    optimizer = optimizer_class(model.parameters(), lr=lr)\n\n    num_epochs = 10\n    train_losses = []\n    results = []\n\n    for epoch in range(num_epochs):\n        epoch_loss = 0.0\n        start_time = time.time()  # Start time for the epoch\n        \n        for raw, reference in dataloader:\n            raw, reference = raw.to(device), reference.to(device)  # Move data to GPU\n            optimizer.zero_grad()\n            outputs = model(raw)\n            loss = criterion(outputs, reference)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item() * raw.size(0)\n\n        epoch_loss /= len(dataloader.dataset)\n        train_losses.append(epoch_loss)\n        end_time = time.time()  # End time for the epoch\n        elapsed_time = end_time - start_time\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Time Taken: {elapsed_time:.2f}s\")\n        results.append({'batch_size': batch_size, 'learning_rate': lr, 'optimizer': optimizer_name,\n                        'epoch': epoch + 1, 'loss': epoch_loss, 'time_taken': elapsed_time})\n\n    # Save loss plot\n    plot_loss(train_losses, output_dir=output_dir, batch_size=batch_size, lr=lr, optimizer_name=optimizer_name)\n    \n    # Save results to CSV\n    df = pd.DataFrame(results)\n    csv_filename = f'results_bs{batch_size}_lr{lr}_opt{optimizer_name}.csv'\n    df.to_csv(os.path.join(output_dir, csv_filename), index=False)\n\n# Grid search\nall_results = []\nfor batch_size in batch_sizes:\n    for lr in learning_rates:\n        for optimizer_name in optimizers.keys():\n            train_and_evaluate(batch_size, lr, optimizer_name)\n            all_results.append((batch_size, lr, optimizer_name))\n\n# Plotting the comparative analysis similar to the provided image\ndef plot_comparative_analysis(output_dir, all_results):\n    data = []\n    for (batch_size, lr, optimizer_name) in all_results:\n        csv_filename = f'results_bs{batch_size}_lr{lr}_opt{optimizer_name}.csv'\n        df = pd.read_csv(os.path.join(output_dir, csv_filename))\n        final_loss = df['loss'].iloc[-1]  # Get the final loss value\n        data.append((batch_size, lr, optimizer_name, final_loss))\n\n    # Create a DataFrame for plotting\n    comparative_df = pd.DataFrame(data, columns=['Batch Size', 'Learning Rate', 'Optimizer', 'Final Loss'])\n\n    # Plot the comparative analysis\n    plt.figure(figsize=(12, 6))\n    \n    markers = ['o', 's', 'D', '^', 'v', '*', 'x', '+']\n    for i, optimizer_name in enumerate(optimizers.keys()):\n        subset = comparative_df[comparative_df['Optimizer'] == optimizer_name]\n        plt.plot(subset['Learning Rate'], subset['Final Loss'], label=optimizer_name, marker=markers[i % len(markers)])\n        \n        # Highlight the best-performing point for each optimizer\n        best_index = subset['Final Loss'].idxmin()\n        best_lr = subset.loc[best_index, 'Learning Rate']\n        best_loss = subset.loc[best_index, 'Final Loss']\n        plt.scatter(best_lr, best_loss, color='red', s=100, edgecolor='black', zorder=5)\n\n    plt.xlabel('Learning Rate')\n    plt.ylabel('Final Loss')\n    plt.title('Comparative Analysis of Optimizers and Learning Rates')\n    plt.xscale('log')\n    plt.grid(True, which=\"both\", ls=\"--\")\n    plt.legend(loc='upper right')\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'comparative_analysis.png'))\n    plt.show()\n\n# Plot and save the comparative analysis\nplot_comparative_analysis(output_dir, all_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:32:26.187284Z","iopub.status.idle":"2024-08-29T14:32:26.187740Z","shell.execute_reply.started":"2024-08-29T14:32:26.187511Z","shell.execute_reply":"2024-08-29T14:32:26.187530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluation code from github with normalizing images \nimport os\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch\nfrom torchvision.utils import save_image\n\n# Check for GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Load saved model\nmodel = torch.load('/kaggle/input/data2-finalmodels/final_model.pt')\nmodel.to(device)  # Ensure the model is on the correct device (GPU or CPU)\nprint(\"Full model loaded successfully!\")\n\n# Optional: Check some of the model's parameters to confirm loading\nfor name, param in model.named_parameters():\n    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]}\")  # Print the first two values\n    break  # Remove or modify this to print more layers or parameters\n\n# Define the RawImageDataset\nclass RawImageDataset(Dataset):\n    def __init__(self, raw_dir, transform=None):\n        self.raw_dir = raw_dir\n        self.transform = transform\n        self.raw_image_paths = [os.path.join(raw_dir, img) for img in os.listdir(raw_dir)]\n\n    def __len__(self):\n        return len(self.raw_image_paths)\n\n    def __getitem__(self, idx):\n        raw_image_path = self.raw_image_paths[idx]\n        raw_image = Image.open(raw_image_path).convert(\"RGB\")\n        \n        if self.transform:\n            raw_image = self.transform(raw_image)\n        \n        return raw_image, os.path.basename(raw_image_path)  # Return the image and its filename\n   \n    # Dataset and DataLoader\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])\n\n# Adjust the path for the raw test images\ntest_dataset = RawImageDataset('/kaggle/input/imgenh-2/dataset-2/Test/Raw', transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# Save all enhanced test images with the same names as input images\nos.makedirs('enhanced_test_images', exist_ok=True)\nmodel.eval()\nwith torch.no_grad():\n    for i, (images, image_names) in enumerate(test_loader):\n        images = images.to(device)\n        outputs = model(images)\n        for j in range(images.size(0)):\n            # Save the output image with the same name as the input image\n            save_image(outputs[j].cpu(), os.path.join('enhanced_test_images', image_names[j]))\n\nprint('All enhanced test images saved!')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T05:46:14.868898Z","iopub.execute_input":"2024-09-16T05:46:14.869236Z","iopub.status.idle":"2024-09-16T05:48:01.545625Z","shell.execute_reply.started":"2024-09-16T05:46:14.869211Z","shell.execute_reply":"2024-09-16T05:48:01.544657Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Full model loaded successfully!\nLayer: inception_block_r.branch1.0.weight | Size: torch.Size([64, 1, 1, 1]) | Values : tensor([[[[ 0.8855]]],\n\n\n        [[[-0.0899]]]], device='cuda:0', grad_fn=<SliceBackward0>)\nAll enhanced test images saved!\n","output_type":"stream"}]},{"cell_type":"code","source":"#EVALUATION METRICS CODE\n#UIQM FILE CONTENT\nimport os\nimport cv2\nimport numpy as np\nfrom skimage import data, color\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal as sig\nimport math\nfrom skimage.util import img_as_ubyte, img_as_float64\nfrom skimage.color import rgb2gray\nfrom skimage.color import rgb2hsv\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nimport warnings\nwarnings.filterwarnings('ignore')\nimport skimage\nfrom numpy import load\nfrom numpy import expand_dims\nimport matplotlib\nfrom matplotlib import pyplot\nimport sys\nimport PIL\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport scipy.misc\nimport imageio\nimport glob\nimport os\nimport cv2\n!pip install sewar\nimport sewar\nimport math\nfrom math import log2, log10\nfrom scipy import ndimage\nimport skimage\nfrom skimage import color\nfrom skimage.metrics import structural_similarity\ndef mu_a(x, alpha_L=0.1, alpha_R=0.1):\n    \"\"\"\n      Calculates the asymetric alpha-trimmed mean\n    \"\"\"\n    # sort pixels by intensity - for clipping\n    x = sorted(x)\n    # get number of pixels\n    K = len(x)\n    # calculate T alpha L and T alpha R\n    T_a_L = math.ceil(alpha_L*K)\n    T_a_R = math.floor(alpha_R*K)\n    # calculate mu_alpha weight\n    weight = (1/(K-T_a_L-T_a_R))\n    # loop through flattened image starting at T_a_L+1 and ending at K-T_a_R\n    s   = int(T_a_L+1)\n    e   = int(K-T_a_R)\n    val = sum(x[s:e])\n    val = weight*val\n    return val\n\ndef s_a(x, mu):\n    val = 0\n    for pixel in x:\n        val += math.pow((pixel-mu), 2)\n    return val/len(x)\n\ndef _uicm(x):\n    R = x[:,:,0].flatten()\n    G = x[:,:,1].flatten()\n    B = x[:,:,2].flatten()\n    RG = R-G\n    YB = ((R+G)/2)-B\n    mu_a_RG = mu_a(RG)\n    mu_a_YB = mu_a(YB)\n    s_a_RG = s_a(RG, mu_a_RG)\n    s_a_YB = s_a(YB, mu_a_YB)\n    l = math.sqrt( (math.pow(mu_a_RG,2)+math.pow(mu_a_YB,2)) )\n    r = math.sqrt(s_a_RG+s_a_YB)\n    return (-0.0268*l)+(0.1586*r)\n\ndef sobel(x):\n    dx = ndimage.sobel(x,0)\n    dy = ndimage.sobel(x,1)\n    mag = np.hypot(dx, dy)\n    mag *= 255.0 / np.max(mag)\n    return mag\n\ndef eme(x, window_size):\n    \"\"\"\n      Enhancement measure estimation\n      x.shape[0] = height\n      x.shape[1] = width\n    \"\"\"\n    # if 4 blocks, then 2x2...etc.\n    k1 = x.shape[1]/window_size\n    k2 = x.shape[0]/window_size\n    # weight\n    w = 2./(k1*k2)\n    blocksize_x = window_size\n    blocksize_y = window_size\n    # make sure image is divisible by window_size - doesn't matter if we cut out some pixels\n    x = x[:int(blocksize_y*k2), :int(blocksize_x*k1)]\n    val = 0\n    for l in range(int(k1)):\n        for k in range(int(k2)):\n            block = x[k*window_size:window_size*(k+1), l*window_size:window_size*(l+1)]\n            max_ = np.max(block)\n            min_ = np.min(block)\n            # bound checks, can't do log(0)\n            if min_ == 0.0: val += 0\n            elif max_ == 0.0: val += 0\n            else: val += math.log(max_/min_)\n    return w*val\n\ndef _uism(x):\n    \"\"\"\n      Underwater Image Sharpness Measure\n    \"\"\"\n    # get image channels\n    R = x[:,:,0]\n    G = x[:,:,1]\n    B = x[:,:,2]\n    # first apply Sobel edge detector to each RGB component\n    Rs = sobel(R)\n    Gs = sobel(G)\n    Bs = sobel(B)\n    # multiply the edges detected for each channel by the channel itself\n    R_edge_map = np.multiply(Rs, R)\n    G_edge_map = np.multiply(Gs, G)\n    B_edge_map = np.multiply(Bs, B)\n    # get eme for each channel\n    r_eme = eme(R_edge_map, 10)\n    g_eme = eme(G_edge_map, 10)\n    b_eme = eme(B_edge_map, 10)\n    # coefficients\n    lambda_r = 0.299\n    lambda_g = 0.587\n    lambda_b = 0.144\n    return (lambda_r*r_eme) + (lambda_g*g_eme) + (lambda_b*b_eme)\n\ndef plip_g(x,mu=1026.0):\n    return mu-x\n\ndef plip_theta(g1, g2, k):\n    g1 = plip_g(g1)\n    g2 = plip_g(g2)\n    return k*((g1-g2)/(k-g2))\n\ndef plip_cross(g1, g2, gamma):\n    g1 = plip_g(g1)\n    g2 = plip_g(g2)\n    return g1+g2-((g1*g2)/(gamma))\n\ndef plip_diag(c, g, gamma):\n    g = plip_g(g)\n    return gamma - (gamma * math.pow((1 - (g/gamma) ), c) )\n\ndef plip_multiplication(g1, g2):\n    return plip_phiInverse(plip_phi(g1) * plip_phi(g2))\n    #return plip_phiInverse(plip_phi(plip_g(g1)) * plip_phi(plip_g(g2)))\n\ndef plip_phiInverse(g):\n    plip_lambda = 1026.0\n    plip_beta   = 1.0\n    return plip_lambda * (1 - math.pow(math.exp(-g / plip_lambda), 1 / plip_beta));\n\ndef plip_phi(g):\n    plip_lambda = 1026.0\n    plip_beta   = 1.0\n    return -plip_lambda * math.pow(math.log(1 - g / plip_lambda), plip_beta)\n\ndef _uiconm(x, window_size):\n    plip_lambda = 1026.0\n    plip_gamma  = 1026.0\n    plip_beta   = 1.0\n    plip_mu     = 1026.0\n    plip_k      = 1026.0\n    # if 4 blocks, then 2x2...etc.\n    k1 = x.shape[1]/window_size\n    k2 = x.shape[0]/window_size\n    # weight\n    w = -1./(k1*k2)\n    blocksize_x = window_size\n    blocksize_y = window_size\n    # make sure image is divisible by window_size - doesn't matter if we cut out some pixels\n    x = x[:int(blocksize_y*k2), :int(blocksize_x*k1)]\n    # entropy scale - higher helps with randomness\n    alpha = 1\n    val = 0\n    for l in range(int(k1)):\n        for k in range(int(k2)):\n            block = x[k*window_size:window_size*(k+1), l*window_size:window_size*(l+1), :]\n            max_ = np.max(block)\n            min_ = np.min(block)\n            top = max_-min_\n            bot = max_+min_\n            if math.isnan(top) or math.isnan(bot) or bot == 0.0 or top == 0.0: val += 0.0\n            else: val += alpha*math.pow((top/bot),alpha) * math.log(top/bot)\n            #try: val += plip_multiplication((top/bot),math.log(top/bot))\n    return w*val\n\n##########################################################################################\n\ndef getUIQM(x):\n    \"\"\"\n      Function to return UIQM to be called from other programs\n      x: image\n    \"\"\"\n    x = x.astype(np.float32)\n    ### from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7300447\n    #c1 = 0.4680; c2 = 0.2745; c3 = 0.2576\n    ### from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7300447\n    c1 = 0.0282; c2 = 0.2953; c3 = 3.5753\n    uicm   = _uicm(x)\n    uism   = _uism(x)\n    uiconm = _uiconm(x, 10)\n    uiqm = (c1*uicm) + (c2*uism) + (c3*uiconm)\n    return uiqm\n\n\ndef getUCIQE(rgb_in):\n    # calculate Chroma\n    rgb_in = cv2.normalize(rgb_in, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    (l,a,b)=cv2.split(rgb_in)\n    Chroma = np.sqrt(a*a + b*b)\n    StdVarianceChroma = np.std(np.reshape(Chroma[:,:],(-1,1)))\n\n    hsv = skimage.color.rgb2hsv(rgb_in)\n    Saturation = hsv[:,:,2]\n    MeanSaturation = np.mean(np.reshape(Saturation[:,:],(-1,1)))\n\n    ContrastLuminance = max(np.reshape(l[:,:],(-1,1))) - min(np.reshape(l[:,:],(-1,1)))\n    UCIQE = 0.4680 * StdVarianceChroma + 0.2745 * ContrastLuminance + 0.2576 * MeanSaturation\n    return float(UCIQE)\n\ndef improve_contrast_image_using_clahe(bgr_image):\n    hsv = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)\n    hsv_planes = cv2.split(hsv)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    hsv_planes[2] = clahe.apply(hsv_planes[2])\n    hsv = cv2.merge(hsv_planes)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T05:48:31.498427Z","iopub.execute_input":"2024-09-16T05:48:31.499043Z","iopub.status.idle":"2024-09-16T05:48:47.222497Z","shell.execute_reply.started":"2024-09-16T05:48:31.499005Z","shell.execute_reply":"2024-09-16T05:48:47.221492Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting sewar\n  Downloading sewar-0.4.6.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sewar) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sewar) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sewar) (9.5.0)\nBuilding wheels for collected packages: sewar\n  Building wheel for sewar (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sewar: filename=sewar-0.4.6-py3-none-any.whl size=11420 sha256=d2d94363ae2ae094d3ba00bb0286e0fd1f28c6c41147c5cbf97f333483606ebf\n  Stored in directory: /root/.cache/pip/wheels/3f/af/02/9c6556ba287b62a945d737def09b8b8c35c9e1d82b9dfae84c\nSuccessfully built sewar\nInstalling collected packages: sewar\nSuccessfully installed sewar-0.4.6\n","output_type":"stream"}]},{"cell_type":"code","source":"from skimage.metrics import structural_similarity, peak_signal_noise_ratio, mean_squared_error\nimport numpy as np\n!pip install libsvm-official\nfrom libsvm.svmutil import *\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport skimage\nimport imageio as iio\n\ndef NormalizeData(data):\n    return (data - np.min(data)) / (np.max(data) - np.min(data))\n\ngenerated = []\ngt = []\n\n# SET THE TEST IMAGE PATH IN gt_addrr\ngt_addrr = \"/kaggle/input/imgenh-2/dataset-2/Test/Reference\"\n\n# SET THE ENHANCED TEST IMAGE PATH IN addrr\naddrr = \"/kaggle/working/enhanced_test_images\"\n\n# Ensure both lists of images have the same order by sorting the filenames\ngt_filenames = sorted(os.listdir(gt_addrr))\ngenerated_filenames = sorted(os.listdir(addrr))\n\n# Load the images, resize them, and append them to the lists\nfor item in generated_filenames:\n    if item.endswith(\".jpg\"):\n        image_path = os.path.join(addrr, item)\n        image = cv2.imread(image_path)\n        if image is not None:  # Ensure the image was loaded\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(\"float32\")\n            image = cv2.resize(image, (256, 256))  # Resize to a common size\n            generated.append(image)\n        else:\n            print(f\"Warning: Could not load image {image_path}\")\n\nfor item in gt_filenames:\n    if item.endswith(\".jpg\"):\n        image_path = os.path.join(gt_addrr, item)\n        image = cv2.imread(image_path)\n        if image is not None:  # Ensure the image was loaded\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(\"float32\")\n            image = cv2.resize(image, (256, 256))  # Resize to a common size\n            gt.append(image)\n        else:\n            print(f\"Warning: Could not load image {image_path}\")\n\n# Ensure both lists have the same length before proceeding\nif len(generated) != len(gt):\n    raise ValueError(\"The number of generated images and ground truth images do not match!\")\n\n# Initialize lists to store the metrics\nSSIM_results = []\nPSNR_results = []\nUIQM = []\nUCIQE = []\nMSE = []\n\n# Calculate metrics for each image pair\nfor i in range(len(generated)):\n    print(f\"Processing image pair {i+1}/{len(generated)}\")\n    \n    # Normalize images\n    norm_generated = NormalizeData(generated[i])\n    norm_gt = NormalizeData(gt[i])\n    \n    # Calculate and store UIQM and UCIQE metrics\n    UIQM.append(getUIQM(norm_generated))\n    UCIQE.append(getUCIQE(norm_generated))\n    \n    # Calculate and store PSNR and SSIM with explicit win_size, channel_axis, and data_range\n    PSNR_results.append(peak_signal_noise_ratio(norm_generated, norm_gt, data_range=1.0))\n    SSIM_results.append(structural_similarity(norm_generated, norm_gt, win_size=7, channel_axis=-1, data_range=1.0))\n    \n    # Calculate and store MSE\n    MSE.append(mean_squared_error(norm_generated, norm_gt))\n\n# Print the average of the metrics\nprint(f\"Average SSIM: {np.mean(SSIM_results):.4f}\")\nprint(f\"Average PSNR: {np.mean(PSNR_results):.4f} dB\")\nprint(f\"Average MSE: {np.mean(MSE):.4f}\")\nprint(f\"Average UIQM: {np.mean(UIQM):.4f}\")\nprint(f\"Average UCIQE: {np.mean(UCIQE):.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T05:48:55.815295Z","iopub.execute_input":"2024-09-16T05:48:55.816112Z","iopub.status.idle":"2024-09-16T06:00:47.136545Z","shell.execute_reply.started":"2024-09-16T05:48:55.816076Z","shell.execute_reply":"2024-09-16T06:00:47.135465Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting libsvm-official\n  Downloading libsvm_official-3.35.0.tar.gz (39 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from libsvm-official) (1.11.4)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->libsvm-official) (1.26.4)\nBuilding wheels for collected packages: libsvm-official\n  Building wheel for libsvm-official (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for libsvm-official: filename=libsvm_official-3.35.0-cp310-cp310-linux_x86_64.whl size=53027 sha256=8ef4976e642e7c001518530e09bcd551cf5f4ae603db3b11aedc8958a56c4a97\n  Stored in directory: /root/.cache/pip/wheels/ec/50/a6/962c82577759a39080b2d0b51640bc1be45d02bd5d0d5dde7d\nSuccessfully built libsvm-official\nInstalling collected packages: libsvm-official\nSuccessfully installed libsvm-official-3.35.0\nProcessing image pair 1/1806\nProcessing image pair 2/1806\nProcessing image pair 3/1806\nProcessing image pair 4/1806\nProcessing image pair 5/1806\nProcessing image pair 6/1806\nProcessing image pair 7/1806\nProcessing image pair 8/1806\nProcessing image pair 9/1806\nProcessing image pair 10/1806\nProcessing image pair 11/1806\nProcessing image pair 12/1806\nProcessing image pair 13/1806\nProcessing image pair 14/1806\nProcessing image pair 15/1806\nProcessing image pair 16/1806\nProcessing image pair 17/1806\nProcessing image pair 18/1806\nProcessing image pair 19/1806\nProcessing image pair 20/1806\nProcessing image pair 21/1806\nProcessing image pair 22/1806\nProcessing image pair 23/1806\nProcessing image pair 24/1806\nProcessing image pair 25/1806\nProcessing image pair 26/1806\nProcessing image pair 27/1806\nProcessing image pair 28/1806\nProcessing image pair 29/1806\nProcessing image pair 30/1806\nProcessing image pair 31/1806\nProcessing image pair 32/1806\nProcessing image pair 33/1806\nProcessing image pair 34/1806\nProcessing image pair 35/1806\nProcessing image pair 36/1806\nProcessing image pair 37/1806\nProcessing image pair 38/1806\nProcessing image pair 39/1806\nProcessing image pair 40/1806\nProcessing image pair 41/1806\nProcessing image pair 42/1806\nProcessing image pair 43/1806\nProcessing image pair 44/1806\nProcessing image pair 45/1806\nProcessing image pair 46/1806\nProcessing image pair 47/1806\nProcessing image pair 48/1806\nProcessing image pair 49/1806\nProcessing image pair 50/1806\nProcessing image pair 51/1806\nProcessing image pair 52/1806\nProcessing image pair 53/1806\nProcessing image pair 54/1806\nProcessing image pair 55/1806\nProcessing image pair 56/1806\nProcessing image pair 57/1806\nProcessing image pair 58/1806\nProcessing image pair 59/1806\nProcessing image pair 60/1806\nProcessing image pair 61/1806\nProcessing image pair 62/1806\nProcessing image pair 63/1806\nProcessing image pair 64/1806\nProcessing image pair 65/1806\nProcessing image pair 66/1806\nProcessing image pair 67/1806\nProcessing image pair 68/1806\nProcessing image pair 69/1806\nProcessing image pair 70/1806\nProcessing image pair 71/1806\nProcessing image pair 72/1806\nProcessing image pair 73/1806\nProcessing image pair 74/1806\nProcessing image pair 75/1806\nProcessing image pair 76/1806\nProcessing image pair 77/1806\nProcessing image pair 78/1806\nProcessing image pair 79/1806\nProcessing image pair 80/1806\nProcessing image pair 81/1806\nProcessing image pair 82/1806\nProcessing image pair 83/1806\nProcessing image pair 84/1806\nProcessing image pair 85/1806\nProcessing image pair 86/1806\nProcessing image pair 87/1806\nProcessing image pair 88/1806\nProcessing image pair 89/1806\nProcessing image pair 90/1806\nProcessing image pair 91/1806\nProcessing image pair 92/1806\nProcessing image pair 93/1806\nProcessing image pair 94/1806\nProcessing image pair 95/1806\nProcessing image pair 96/1806\nProcessing image pair 97/1806\nProcessing image pair 98/1806\nProcessing image pair 99/1806\nProcessing image pair 100/1806\nProcessing image pair 101/1806\nProcessing image pair 102/1806\nProcessing image pair 103/1806\nProcessing image pair 104/1806\nProcessing image pair 105/1806\nProcessing image pair 106/1806\nProcessing image pair 107/1806\nProcessing image pair 108/1806\nProcessing image pair 109/1806\nProcessing image pair 110/1806\nProcessing image pair 111/1806\nProcessing image pair 112/1806\nProcessing image pair 113/1806\nProcessing image pair 114/1806\nProcessing image pair 115/1806\nProcessing image pair 116/1806\nProcessing image pair 117/1806\nProcessing image pair 118/1806\nProcessing image pair 119/1806\nProcessing image pair 120/1806\nProcessing image pair 121/1806\nProcessing image pair 122/1806\nProcessing image pair 123/1806\nProcessing image pair 124/1806\nProcessing image pair 125/1806\nProcessing image pair 126/1806\nProcessing image pair 127/1806\nProcessing image pair 128/1806\nProcessing image pair 129/1806\nProcessing image pair 130/1806\nProcessing image pair 131/1806\nProcessing image pair 132/1806\nProcessing image pair 133/1806\nProcessing image pair 134/1806\nProcessing image pair 135/1806\nProcessing image pair 136/1806\nProcessing image pair 137/1806\nProcessing image pair 138/1806\nProcessing image pair 139/1806\nProcessing image pair 140/1806\nProcessing image pair 141/1806\nProcessing image pair 142/1806\nProcessing image pair 143/1806\nProcessing image pair 144/1806\nProcessing image pair 145/1806\nProcessing image pair 146/1806\nProcessing image pair 147/1806\nProcessing image pair 148/1806\nProcessing image pair 149/1806\nProcessing image pair 150/1806\nProcessing image pair 151/1806\nProcessing image pair 152/1806\nProcessing image pair 153/1806\nProcessing image pair 154/1806\nProcessing image pair 155/1806\nProcessing image pair 156/1806\nProcessing image pair 157/1806\nProcessing image pair 158/1806\nProcessing image pair 159/1806\nProcessing image pair 160/1806\nProcessing image pair 161/1806\nProcessing image pair 162/1806\nProcessing image pair 163/1806\nProcessing image pair 164/1806\nProcessing image pair 165/1806\nProcessing image pair 166/1806\nProcessing image pair 167/1806\nProcessing image pair 168/1806\nProcessing image pair 169/1806\nProcessing image pair 170/1806\nProcessing image pair 171/1806\nProcessing image pair 172/1806\nProcessing image pair 173/1806\nProcessing image pair 174/1806\nProcessing image pair 175/1806\nProcessing image pair 176/1806\nProcessing image pair 177/1806\nProcessing image pair 178/1806\nProcessing image pair 179/1806\nProcessing image pair 180/1806\nProcessing image pair 181/1806\nProcessing image pair 182/1806\nProcessing image pair 183/1806\nProcessing image pair 184/1806\nProcessing image pair 185/1806\nProcessing image pair 186/1806\nProcessing image pair 187/1806\nProcessing image pair 188/1806\nProcessing image pair 189/1806\nProcessing image pair 190/1806\nProcessing image pair 191/1806\nProcessing image pair 192/1806\nProcessing image pair 193/1806\nProcessing image pair 194/1806\nProcessing image pair 195/1806\nProcessing image pair 196/1806\nProcessing image pair 197/1806\nProcessing image pair 198/1806\nProcessing image pair 199/1806\nProcessing image pair 200/1806\nProcessing image pair 201/1806\nProcessing image pair 202/1806\nProcessing image pair 203/1806\nProcessing image pair 204/1806\nProcessing image pair 205/1806\nProcessing image pair 206/1806\nProcessing image pair 207/1806\nProcessing image pair 208/1806\nProcessing image pair 209/1806\nProcessing image pair 210/1806\nProcessing image pair 211/1806\nProcessing image pair 212/1806\nProcessing image pair 213/1806\nProcessing image pair 214/1806\nProcessing image pair 215/1806\nProcessing image pair 216/1806\nProcessing image pair 217/1806\nProcessing image pair 218/1806\nProcessing image pair 219/1806\nProcessing image pair 220/1806\nProcessing image pair 221/1806\nProcessing image pair 222/1806\nProcessing image pair 223/1806\nProcessing image pair 224/1806\nProcessing image pair 225/1806\nProcessing image pair 226/1806\nProcessing image pair 227/1806\nProcessing image pair 228/1806\nProcessing image pair 229/1806\nProcessing image pair 230/1806\nProcessing image pair 231/1806\nProcessing image pair 232/1806\nProcessing image pair 233/1806\nProcessing image pair 234/1806\nProcessing image pair 235/1806\nProcessing image pair 236/1806\nProcessing image pair 237/1806\nProcessing image pair 238/1806\nProcessing image pair 239/1806\nProcessing image pair 240/1806\nProcessing image pair 241/1806\nProcessing image pair 242/1806\nProcessing image pair 243/1806\nProcessing image pair 244/1806\nProcessing image pair 245/1806\nProcessing image pair 246/1806\nProcessing image pair 247/1806\nProcessing image pair 248/1806\nProcessing image pair 249/1806\nProcessing image pair 250/1806\nProcessing image pair 251/1806\nProcessing image pair 252/1806\nProcessing image pair 253/1806\nProcessing image pair 254/1806\nProcessing image pair 255/1806\nProcessing image pair 256/1806\nProcessing image pair 257/1806\nProcessing image pair 258/1806\nProcessing image pair 259/1806\nProcessing image pair 260/1806\nProcessing image pair 261/1806\nProcessing image pair 262/1806\nProcessing image pair 263/1806\nProcessing image pair 264/1806\nProcessing image pair 265/1806\nProcessing image pair 266/1806\nProcessing image pair 267/1806\nProcessing image pair 268/1806\nProcessing image pair 269/1806\nProcessing image pair 270/1806\nProcessing image pair 271/1806\nProcessing image pair 272/1806\nProcessing image pair 273/1806\nProcessing image pair 274/1806\nProcessing image pair 275/1806\nProcessing image pair 276/1806\nProcessing image pair 277/1806\nProcessing image pair 278/1806\nProcessing image pair 279/1806\nProcessing image pair 280/1806\nProcessing image pair 281/1806\nProcessing image pair 282/1806\nProcessing image pair 283/1806\nProcessing image pair 284/1806\nProcessing image pair 285/1806\nProcessing image pair 286/1806\nProcessing image pair 287/1806\nProcessing image pair 288/1806\nProcessing image pair 289/1806\nProcessing image pair 290/1806\nProcessing image pair 291/1806\nProcessing image pair 292/1806\nProcessing image pair 293/1806\nProcessing image pair 294/1806\nProcessing image pair 295/1806\nProcessing image pair 296/1806\nProcessing image pair 297/1806\nProcessing image pair 298/1806\nProcessing image pair 299/1806\nProcessing image pair 300/1806\nProcessing image pair 301/1806\nProcessing image pair 302/1806\nProcessing image pair 303/1806\nProcessing image pair 304/1806\nProcessing image pair 305/1806\nProcessing image pair 306/1806\nProcessing image pair 307/1806\nProcessing image pair 308/1806\nProcessing image pair 309/1806\nProcessing image pair 310/1806\nProcessing image pair 311/1806\nProcessing image pair 312/1806\nProcessing image pair 313/1806\nProcessing image pair 314/1806\nProcessing image pair 315/1806\nProcessing image pair 316/1806\nProcessing image pair 317/1806\nProcessing image pair 318/1806\nProcessing image pair 319/1806\nProcessing image pair 320/1806\nProcessing image pair 321/1806\nProcessing image pair 322/1806\nProcessing image pair 323/1806\nProcessing image pair 324/1806\nProcessing image pair 325/1806\nProcessing image pair 326/1806\nProcessing image pair 327/1806\nProcessing image pair 328/1806\nProcessing image pair 329/1806\nProcessing image pair 330/1806\nProcessing image pair 331/1806\nProcessing image pair 332/1806\nProcessing image pair 333/1806\nProcessing image pair 334/1806\nProcessing image pair 335/1806\nProcessing image pair 336/1806\nProcessing image pair 337/1806\nProcessing image pair 338/1806\nProcessing image pair 339/1806\nProcessing image pair 340/1806\nProcessing image pair 341/1806\nProcessing image pair 342/1806\nProcessing image pair 343/1806\nProcessing image pair 344/1806\nProcessing image pair 345/1806\nProcessing image pair 346/1806\nProcessing image pair 347/1806\nProcessing image pair 348/1806\nProcessing image pair 349/1806\nProcessing image pair 350/1806\nProcessing image pair 351/1806\nProcessing image pair 352/1806\nProcessing image pair 353/1806\nProcessing image pair 354/1806\nProcessing image pair 355/1806\nProcessing image pair 356/1806\nProcessing image pair 357/1806\nProcessing image pair 358/1806\nProcessing image pair 359/1806\nProcessing image pair 360/1806\nProcessing image pair 361/1806\nProcessing image pair 362/1806\nProcessing image pair 363/1806\nProcessing image pair 364/1806\nProcessing image pair 365/1806\nProcessing image pair 366/1806\nProcessing image pair 367/1806\nProcessing image pair 368/1806\nProcessing image pair 369/1806\nProcessing image pair 370/1806\nProcessing image pair 371/1806\nProcessing image pair 372/1806\nProcessing image pair 373/1806\nProcessing image pair 374/1806\nProcessing image pair 375/1806\nProcessing image pair 376/1806\nProcessing image pair 377/1806\nProcessing image pair 378/1806\nProcessing image pair 379/1806\nProcessing image pair 380/1806\nProcessing image pair 381/1806\nProcessing image pair 382/1806\nProcessing image pair 383/1806\nProcessing image pair 384/1806\nProcessing image pair 385/1806\nProcessing image pair 386/1806\nProcessing image pair 387/1806\nProcessing image pair 388/1806\nProcessing image pair 389/1806\nProcessing image pair 390/1806\nProcessing image pair 391/1806\nProcessing image pair 392/1806\nProcessing image pair 393/1806\nProcessing image pair 394/1806\nProcessing image pair 395/1806\nProcessing image pair 396/1806\nProcessing image pair 397/1806\nProcessing image pair 398/1806\nProcessing image pair 399/1806\nProcessing image pair 400/1806\nProcessing image pair 401/1806\nProcessing image pair 402/1806\nProcessing image pair 403/1806\nProcessing image pair 404/1806\nProcessing image pair 405/1806\nProcessing image pair 406/1806\nProcessing image pair 407/1806\nProcessing image pair 408/1806\nProcessing image pair 409/1806\nProcessing image pair 410/1806\nProcessing image pair 411/1806\nProcessing image pair 412/1806\nProcessing image pair 413/1806\nProcessing image pair 414/1806\nProcessing image pair 415/1806\nProcessing image pair 416/1806\nProcessing image pair 417/1806\nProcessing image pair 418/1806\nProcessing image pair 419/1806\nProcessing image pair 420/1806\nProcessing image pair 421/1806\nProcessing image pair 422/1806\nProcessing image pair 423/1806\nProcessing image pair 424/1806\nProcessing image pair 425/1806\nProcessing image pair 426/1806\nProcessing image pair 427/1806\nProcessing image pair 428/1806\nProcessing image pair 429/1806\nProcessing image pair 430/1806\nProcessing image pair 431/1806\nProcessing image pair 432/1806\nProcessing image pair 433/1806\nProcessing image pair 434/1806\nProcessing image pair 435/1806\nProcessing image pair 436/1806\nProcessing image pair 437/1806\nProcessing image pair 438/1806\nProcessing image pair 439/1806\nProcessing image pair 440/1806\nProcessing image pair 441/1806\nProcessing image pair 442/1806\nProcessing image pair 443/1806\nProcessing image pair 444/1806\nProcessing image pair 445/1806\nProcessing image pair 446/1806\nProcessing image pair 447/1806\nProcessing image pair 448/1806\nProcessing image pair 449/1806\nProcessing image pair 450/1806\nProcessing image pair 451/1806\nProcessing image pair 452/1806\nProcessing image pair 453/1806\nProcessing image pair 454/1806\nProcessing image pair 455/1806\nProcessing image pair 456/1806\nProcessing image pair 457/1806\nProcessing image pair 458/1806\nProcessing image pair 459/1806\nProcessing image pair 460/1806\nProcessing image pair 461/1806\nProcessing image pair 462/1806\nProcessing image pair 463/1806\nProcessing image pair 464/1806\nProcessing image pair 465/1806\nProcessing image pair 466/1806\nProcessing image pair 467/1806\nProcessing image pair 468/1806\nProcessing image pair 469/1806\nProcessing image pair 470/1806\nProcessing image pair 471/1806\nProcessing image pair 472/1806\nProcessing image pair 473/1806\nProcessing image pair 474/1806\nProcessing image pair 475/1806\nProcessing image pair 476/1806\nProcessing image pair 477/1806\nProcessing image pair 478/1806\nProcessing image pair 479/1806\nProcessing image pair 480/1806\nProcessing image pair 481/1806\nProcessing image pair 482/1806\nProcessing image pair 483/1806\nProcessing image pair 484/1806\nProcessing image pair 485/1806\nProcessing image pair 486/1806\nProcessing image pair 487/1806\nProcessing image pair 488/1806\nProcessing image pair 489/1806\nProcessing image pair 490/1806\nProcessing image pair 491/1806\nProcessing image pair 492/1806\nProcessing image pair 493/1806\nProcessing image pair 494/1806\nProcessing image pair 495/1806\nProcessing image pair 496/1806\nProcessing image pair 497/1806\nProcessing image pair 498/1806\nProcessing image pair 499/1806\nProcessing image pair 500/1806\nProcessing image pair 501/1806\nProcessing image pair 502/1806\nProcessing image pair 503/1806\nProcessing image pair 504/1806\nProcessing image pair 505/1806\nProcessing image pair 506/1806\nProcessing image pair 507/1806\nProcessing image pair 508/1806\nProcessing image pair 509/1806\nProcessing image pair 510/1806\nProcessing image pair 511/1806\nProcessing image pair 512/1806\nProcessing image pair 513/1806\nProcessing image pair 514/1806\nProcessing image pair 515/1806\nProcessing image pair 516/1806\nProcessing image pair 517/1806\nProcessing image pair 518/1806\nProcessing image pair 519/1806\nProcessing image pair 520/1806\nProcessing image pair 521/1806\nProcessing image pair 522/1806\nProcessing image pair 523/1806\nProcessing image pair 524/1806\nProcessing image pair 525/1806\nProcessing image pair 526/1806\nProcessing image pair 527/1806\nProcessing image pair 528/1806\nProcessing image pair 529/1806\nProcessing image pair 530/1806\nProcessing image pair 531/1806\nProcessing image pair 532/1806\nProcessing image pair 533/1806\nProcessing image pair 534/1806\nProcessing image pair 535/1806\nProcessing image pair 536/1806\nProcessing image pair 537/1806\nProcessing image pair 538/1806\nProcessing image pair 539/1806\nProcessing image pair 540/1806\nProcessing image pair 541/1806\nProcessing image pair 542/1806\nProcessing image pair 543/1806\nProcessing image pair 544/1806\nProcessing image pair 545/1806\nProcessing image pair 546/1806\nProcessing image pair 547/1806\nProcessing image pair 548/1806\nProcessing image pair 549/1806\nProcessing image pair 550/1806\nProcessing image pair 551/1806\nProcessing image pair 552/1806\nProcessing image pair 553/1806\nProcessing image pair 554/1806\nProcessing image pair 555/1806\nProcessing image pair 556/1806\nProcessing image pair 557/1806\nProcessing image pair 558/1806\nProcessing image pair 559/1806\nProcessing image pair 560/1806\nProcessing image pair 561/1806\nProcessing image pair 562/1806\nProcessing image pair 563/1806\nProcessing image pair 564/1806\nProcessing image pair 565/1806\nProcessing image pair 566/1806\nProcessing image pair 567/1806\nProcessing image pair 568/1806\nProcessing image pair 569/1806\nProcessing image pair 570/1806\nProcessing image pair 571/1806\nProcessing image pair 572/1806\nProcessing image pair 573/1806\nProcessing image pair 574/1806\nProcessing image pair 575/1806\nProcessing image pair 576/1806\nProcessing image pair 577/1806\nProcessing image pair 578/1806\nProcessing image pair 579/1806\nProcessing image pair 580/1806\nProcessing image pair 581/1806\nProcessing image pair 582/1806\nProcessing image pair 583/1806\nProcessing image pair 584/1806\nProcessing image pair 585/1806\nProcessing image pair 586/1806\nProcessing image pair 587/1806\nProcessing image pair 588/1806\nProcessing image pair 589/1806\nProcessing image pair 590/1806\nProcessing image pair 591/1806\nProcessing image pair 592/1806\nProcessing image pair 593/1806\nProcessing image pair 594/1806\nProcessing image pair 595/1806\nProcessing image pair 596/1806\nProcessing image pair 597/1806\nProcessing image pair 598/1806\nProcessing image pair 599/1806\nProcessing image pair 600/1806\nProcessing image pair 601/1806\nProcessing image pair 602/1806\nProcessing image pair 603/1806\nProcessing image pair 604/1806\nProcessing image pair 605/1806\nProcessing image pair 606/1806\nProcessing image pair 607/1806\nProcessing image pair 608/1806\nProcessing image pair 609/1806\nProcessing image pair 610/1806\nProcessing image pair 611/1806\nProcessing image pair 612/1806\nProcessing image pair 613/1806\nProcessing image pair 614/1806\nProcessing image pair 615/1806\nProcessing image pair 616/1806\nProcessing image pair 617/1806\nProcessing image pair 618/1806\nProcessing image pair 619/1806\nProcessing image pair 620/1806\nProcessing image pair 621/1806\nProcessing image pair 622/1806\nProcessing image pair 623/1806\nProcessing image pair 624/1806\nProcessing image pair 625/1806\nProcessing image pair 626/1806\nProcessing image pair 627/1806\nProcessing image pair 628/1806\nProcessing image pair 629/1806\nProcessing image pair 630/1806\nProcessing image pair 631/1806\nProcessing image pair 632/1806\nProcessing image pair 633/1806\nProcessing image pair 634/1806\nProcessing image pair 635/1806\nProcessing image pair 636/1806\nProcessing image pair 637/1806\nProcessing image pair 638/1806\nProcessing image pair 639/1806\nProcessing image pair 640/1806\nProcessing image pair 641/1806\nProcessing image pair 642/1806\nProcessing image pair 643/1806\nProcessing image pair 644/1806\nProcessing image pair 645/1806\nProcessing image pair 646/1806\nProcessing image pair 647/1806\nProcessing image pair 648/1806\nProcessing image pair 649/1806\nProcessing image pair 650/1806\nProcessing image pair 651/1806\nProcessing image pair 652/1806\nProcessing image pair 653/1806\nProcessing image pair 654/1806\nProcessing image pair 655/1806\nProcessing image pair 656/1806\nProcessing image pair 657/1806\nProcessing image pair 658/1806\nProcessing image pair 659/1806\nProcessing image pair 660/1806\nProcessing image pair 661/1806\nProcessing image pair 662/1806\nProcessing image pair 663/1806\nProcessing image pair 664/1806\nProcessing image pair 665/1806\nProcessing image pair 666/1806\nProcessing image pair 667/1806\nProcessing image pair 668/1806\nProcessing image pair 669/1806\nProcessing image pair 670/1806\nProcessing image pair 671/1806\nProcessing image pair 672/1806\nProcessing image pair 673/1806\nProcessing image pair 674/1806\nProcessing image pair 675/1806\nProcessing image pair 676/1806\nProcessing image pair 677/1806\nProcessing image pair 678/1806\nProcessing image pair 679/1806\nProcessing image pair 680/1806\nProcessing image pair 681/1806\nProcessing image pair 682/1806\nProcessing image pair 683/1806\nProcessing image pair 684/1806\nProcessing image pair 685/1806\nProcessing image pair 686/1806\nProcessing image pair 687/1806\nProcessing image pair 688/1806\nProcessing image pair 689/1806\nProcessing image pair 690/1806\nProcessing image pair 691/1806\nProcessing image pair 692/1806\nProcessing image pair 693/1806\nProcessing image pair 694/1806\nProcessing image pair 695/1806\nProcessing image pair 696/1806\nProcessing image pair 697/1806\nProcessing image pair 698/1806\nProcessing image pair 699/1806\nProcessing image pair 700/1806\nProcessing image pair 701/1806\nProcessing image pair 702/1806\nProcessing image pair 703/1806\nProcessing image pair 704/1806\nProcessing image pair 705/1806\nProcessing image pair 706/1806\nProcessing image pair 707/1806\nProcessing image pair 708/1806\nProcessing image pair 709/1806\nProcessing image pair 710/1806\nProcessing image pair 711/1806\nProcessing image pair 712/1806\nProcessing image pair 713/1806\nProcessing image pair 714/1806\nProcessing image pair 715/1806\nProcessing image pair 716/1806\nProcessing image pair 717/1806\nProcessing image pair 718/1806\nProcessing image pair 719/1806\nProcessing image pair 720/1806\nProcessing image pair 721/1806\nProcessing image pair 722/1806\nProcessing image pair 723/1806\nProcessing image pair 724/1806\nProcessing image pair 725/1806\nProcessing image pair 726/1806\nProcessing image pair 727/1806\nProcessing image pair 728/1806\nProcessing image pair 729/1806\nProcessing image pair 730/1806\nProcessing image pair 731/1806\nProcessing image pair 732/1806\nProcessing image pair 733/1806\nProcessing image pair 734/1806\nProcessing image pair 735/1806\nProcessing image pair 736/1806\nProcessing image pair 737/1806\nProcessing image pair 738/1806\nProcessing image pair 739/1806\nProcessing image pair 740/1806\nProcessing image pair 741/1806\nProcessing image pair 742/1806\nProcessing image pair 743/1806\nProcessing image pair 744/1806\nProcessing image pair 745/1806\nProcessing image pair 746/1806\nProcessing image pair 747/1806\nProcessing image pair 748/1806\nProcessing image pair 749/1806\nProcessing image pair 750/1806\nProcessing image pair 751/1806\nProcessing image pair 752/1806\nProcessing image pair 753/1806\nProcessing image pair 754/1806\nProcessing image pair 755/1806\nProcessing image pair 756/1806\nProcessing image pair 757/1806\nProcessing image pair 758/1806\nProcessing image pair 759/1806\nProcessing image pair 760/1806\nProcessing image pair 761/1806\nProcessing image pair 762/1806\nProcessing image pair 763/1806\nProcessing image pair 764/1806\nProcessing image pair 765/1806\nProcessing image pair 766/1806\nProcessing image pair 767/1806\nProcessing image pair 768/1806\nProcessing image pair 769/1806\nProcessing image pair 770/1806\nProcessing image pair 771/1806\nProcessing image pair 772/1806\nProcessing image pair 773/1806\nProcessing image pair 774/1806\nProcessing image pair 775/1806\nProcessing image pair 776/1806\nProcessing image pair 777/1806\nProcessing image pair 778/1806\nProcessing image pair 779/1806\nProcessing image pair 780/1806\nProcessing image pair 781/1806\nProcessing image pair 782/1806\nProcessing image pair 783/1806\nProcessing image pair 784/1806\nProcessing image pair 785/1806\nProcessing image pair 786/1806\nProcessing image pair 787/1806\nProcessing image pair 788/1806\nProcessing image pair 789/1806\nProcessing image pair 790/1806\nProcessing image pair 791/1806\nProcessing image pair 792/1806\nProcessing image pair 793/1806\nProcessing image pair 794/1806\nProcessing image pair 795/1806\nProcessing image pair 796/1806\nProcessing image pair 797/1806\nProcessing image pair 798/1806\nProcessing image pair 799/1806\nProcessing image pair 800/1806\nProcessing image pair 801/1806\nProcessing image pair 802/1806\nProcessing image pair 803/1806\nProcessing image pair 804/1806\nProcessing image pair 805/1806\nProcessing image pair 806/1806\nProcessing image pair 807/1806\nProcessing image pair 808/1806\nProcessing image pair 809/1806\nProcessing image pair 810/1806\nProcessing image pair 811/1806\nProcessing image pair 812/1806\nProcessing image pair 813/1806\nProcessing image pair 814/1806\nProcessing image pair 815/1806\nProcessing image pair 816/1806\nProcessing image pair 817/1806\nProcessing image pair 818/1806\nProcessing image pair 819/1806\nProcessing image pair 820/1806\nProcessing image pair 821/1806\nProcessing image pair 822/1806\nProcessing image pair 823/1806\nProcessing image pair 824/1806\nProcessing image pair 825/1806\nProcessing image pair 826/1806\nProcessing image pair 827/1806\nProcessing image pair 828/1806\nProcessing image pair 829/1806\nProcessing image pair 830/1806\nProcessing image pair 831/1806\nProcessing image pair 832/1806\nProcessing image pair 833/1806\nProcessing image pair 834/1806\nProcessing image pair 835/1806\nProcessing image pair 836/1806\nProcessing image pair 837/1806\nProcessing image pair 838/1806\nProcessing image pair 839/1806\nProcessing image pair 840/1806\nProcessing image pair 841/1806\nProcessing image pair 842/1806\nProcessing image pair 843/1806\nProcessing image pair 844/1806\nProcessing image pair 845/1806\nProcessing image pair 846/1806\nProcessing image pair 847/1806\nProcessing image pair 848/1806\nProcessing image pair 849/1806\nProcessing image pair 850/1806\nProcessing image pair 851/1806\nProcessing image pair 852/1806\nProcessing image pair 853/1806\nProcessing image pair 854/1806\nProcessing image pair 855/1806\nProcessing image pair 856/1806\nProcessing image pair 857/1806\nProcessing image pair 858/1806\nProcessing image pair 859/1806\nProcessing image pair 860/1806\nProcessing image pair 861/1806\nProcessing image pair 862/1806\nProcessing image pair 863/1806\nProcessing image pair 864/1806\nProcessing image pair 865/1806\nProcessing image pair 866/1806\nProcessing image pair 867/1806\nProcessing image pair 868/1806\nProcessing image pair 869/1806\nProcessing image pair 870/1806\nProcessing image pair 871/1806\nProcessing image pair 872/1806\nProcessing image pair 873/1806\nProcessing image pair 874/1806\nProcessing image pair 875/1806\nProcessing image pair 876/1806\nProcessing image pair 877/1806\nProcessing image pair 878/1806\nProcessing image pair 879/1806\nProcessing image pair 880/1806\nProcessing image pair 881/1806\nProcessing image pair 882/1806\nProcessing image pair 883/1806\nProcessing image pair 884/1806\nProcessing image pair 885/1806\nProcessing image pair 886/1806\nProcessing image pair 887/1806\nProcessing image pair 888/1806\nProcessing image pair 889/1806\nProcessing image pair 890/1806\nProcessing image pair 891/1806\nProcessing image pair 892/1806\nProcessing image pair 893/1806\nProcessing image pair 894/1806\nProcessing image pair 895/1806\nProcessing image pair 896/1806\nProcessing image pair 897/1806\nProcessing image pair 898/1806\nProcessing image pair 899/1806\nProcessing image pair 900/1806\nProcessing image pair 901/1806\nProcessing image pair 902/1806\nProcessing image pair 903/1806\nProcessing image pair 904/1806\nProcessing image pair 905/1806\nProcessing image pair 906/1806\nProcessing image pair 907/1806\nProcessing image pair 908/1806\nProcessing image pair 909/1806\nProcessing image pair 910/1806\nProcessing image pair 911/1806\nProcessing image pair 912/1806\nProcessing image pair 913/1806\nProcessing image pair 914/1806\nProcessing image pair 915/1806\nProcessing image pair 916/1806\nProcessing image pair 917/1806\nProcessing image pair 918/1806\nProcessing image pair 919/1806\nProcessing image pair 920/1806\nProcessing image pair 921/1806\nProcessing image pair 922/1806\nProcessing image pair 923/1806\nProcessing image pair 924/1806\nProcessing image pair 925/1806\nProcessing image pair 926/1806\nProcessing image pair 927/1806\nProcessing image pair 928/1806\nProcessing image pair 929/1806\nProcessing image pair 930/1806\nProcessing image pair 931/1806\nProcessing image pair 932/1806\nProcessing image pair 933/1806\nProcessing image pair 934/1806\nProcessing image pair 935/1806\nProcessing image pair 936/1806\nProcessing image pair 937/1806\nProcessing image pair 938/1806\nProcessing image pair 939/1806\nProcessing image pair 940/1806\nProcessing image pair 941/1806\nProcessing image pair 942/1806\nProcessing image pair 943/1806\nProcessing image pair 944/1806\nProcessing image pair 945/1806\nProcessing image pair 946/1806\nProcessing image pair 947/1806\nProcessing image pair 948/1806\nProcessing image pair 949/1806\nProcessing image pair 950/1806\nProcessing image pair 951/1806\nProcessing image pair 952/1806\nProcessing image pair 953/1806\nProcessing image pair 954/1806\nProcessing image pair 955/1806\nProcessing image pair 956/1806\nProcessing image pair 957/1806\nProcessing image pair 958/1806\nProcessing image pair 959/1806\nProcessing image pair 960/1806\nProcessing image pair 961/1806\nProcessing image pair 962/1806\nProcessing image pair 963/1806\nProcessing image pair 964/1806\nProcessing image pair 965/1806\nProcessing image pair 966/1806\nProcessing image pair 967/1806\nProcessing image pair 968/1806\nProcessing image pair 969/1806\nProcessing image pair 970/1806\nProcessing image pair 971/1806\nProcessing image pair 972/1806\nProcessing image pair 973/1806\nProcessing image pair 974/1806\nProcessing image pair 975/1806\nProcessing image pair 976/1806\nProcessing image pair 977/1806\nProcessing image pair 978/1806\nProcessing image pair 979/1806\nProcessing image pair 980/1806\nProcessing image pair 981/1806\nProcessing image pair 982/1806\nProcessing image pair 983/1806\nProcessing image pair 984/1806\nProcessing image pair 985/1806\nProcessing image pair 986/1806\nProcessing image pair 987/1806\nProcessing image pair 988/1806\nProcessing image pair 989/1806\nProcessing image pair 990/1806\nProcessing image pair 991/1806\nProcessing image pair 992/1806\nProcessing image pair 993/1806\nProcessing image pair 994/1806\nProcessing image pair 995/1806\nProcessing image pair 996/1806\nProcessing image pair 997/1806\nProcessing image pair 998/1806\nProcessing image pair 999/1806\nProcessing image pair 1000/1806\nProcessing image pair 1001/1806\nProcessing image pair 1002/1806\nProcessing image pair 1003/1806\nProcessing image pair 1004/1806\nProcessing image pair 1005/1806\nProcessing image pair 1006/1806\nProcessing image pair 1007/1806\nProcessing image pair 1008/1806\nProcessing image pair 1009/1806\nProcessing image pair 1010/1806\nProcessing image pair 1011/1806\nProcessing image pair 1012/1806\nProcessing image pair 1013/1806\nProcessing image pair 1014/1806\nProcessing image pair 1015/1806\nProcessing image pair 1016/1806\nProcessing image pair 1017/1806\nProcessing image pair 1018/1806\nProcessing image pair 1019/1806\nProcessing image pair 1020/1806\nProcessing image pair 1021/1806\nProcessing image pair 1022/1806\nProcessing image pair 1023/1806\nProcessing image pair 1024/1806\nProcessing image pair 1025/1806\nProcessing image pair 1026/1806\nProcessing image pair 1027/1806\nProcessing image pair 1028/1806\nProcessing image pair 1029/1806\nProcessing image pair 1030/1806\nProcessing image pair 1031/1806\nProcessing image pair 1032/1806\nProcessing image pair 1033/1806\nProcessing image pair 1034/1806\nProcessing image pair 1035/1806\nProcessing image pair 1036/1806\nProcessing image pair 1037/1806\nProcessing image pair 1038/1806\nProcessing image pair 1039/1806\nProcessing image pair 1040/1806\nProcessing image pair 1041/1806\nProcessing image pair 1042/1806\nProcessing image pair 1043/1806\nProcessing image pair 1044/1806\nProcessing image pair 1045/1806\nProcessing image pair 1046/1806\nProcessing image pair 1047/1806\nProcessing image pair 1048/1806\nProcessing image pair 1049/1806\nProcessing image pair 1050/1806\nProcessing image pair 1051/1806\nProcessing image pair 1052/1806\nProcessing image pair 1053/1806\nProcessing image pair 1054/1806\nProcessing image pair 1055/1806\nProcessing image pair 1056/1806\nProcessing image pair 1057/1806\nProcessing image pair 1058/1806\nProcessing image pair 1059/1806\nProcessing image pair 1060/1806\nProcessing image pair 1061/1806\nProcessing image pair 1062/1806\nProcessing image pair 1063/1806\nProcessing image pair 1064/1806\nProcessing image pair 1065/1806\nProcessing image pair 1066/1806\nProcessing image pair 1067/1806\nProcessing image pair 1068/1806\nProcessing image pair 1069/1806\nProcessing image pair 1070/1806\nProcessing image pair 1071/1806\nProcessing image pair 1072/1806\nProcessing image pair 1073/1806\nProcessing image pair 1074/1806\nProcessing image pair 1075/1806\nProcessing image pair 1076/1806\nProcessing image pair 1077/1806\nProcessing image pair 1078/1806\nProcessing image pair 1079/1806\nProcessing image pair 1080/1806\nProcessing image pair 1081/1806\nProcessing image pair 1082/1806\nProcessing image pair 1083/1806\nProcessing image pair 1084/1806\nProcessing image pair 1085/1806\nProcessing image pair 1086/1806\nProcessing image pair 1087/1806\nProcessing image pair 1088/1806\nProcessing image pair 1089/1806\nProcessing image pair 1090/1806\nProcessing image pair 1091/1806\nProcessing image pair 1092/1806\nProcessing image pair 1093/1806\nProcessing image pair 1094/1806\nProcessing image pair 1095/1806\nProcessing image pair 1096/1806\nProcessing image pair 1097/1806\nProcessing image pair 1098/1806\nProcessing image pair 1099/1806\nProcessing image pair 1100/1806\nProcessing image pair 1101/1806\nProcessing image pair 1102/1806\nProcessing image pair 1103/1806\nProcessing image pair 1104/1806\nProcessing image pair 1105/1806\nProcessing image pair 1106/1806\nProcessing image pair 1107/1806\nProcessing image pair 1108/1806\nProcessing image pair 1109/1806\nProcessing image pair 1110/1806\nProcessing image pair 1111/1806\nProcessing image pair 1112/1806\nProcessing image pair 1113/1806\nProcessing image pair 1114/1806\nProcessing image pair 1115/1806\nProcessing image pair 1116/1806\nProcessing image pair 1117/1806\nProcessing image pair 1118/1806\nProcessing image pair 1119/1806\nProcessing image pair 1120/1806\nProcessing image pair 1121/1806\nProcessing image pair 1122/1806\nProcessing image pair 1123/1806\nProcessing image pair 1124/1806\nProcessing image pair 1125/1806\nProcessing image pair 1126/1806\nProcessing image pair 1127/1806\nProcessing image pair 1128/1806\nProcessing image pair 1129/1806\nProcessing image pair 1130/1806\nProcessing image pair 1131/1806\nProcessing image pair 1132/1806\nProcessing image pair 1133/1806\nProcessing image pair 1134/1806\nProcessing image pair 1135/1806\nProcessing image pair 1136/1806\nProcessing image pair 1137/1806\nProcessing image pair 1138/1806\nProcessing image pair 1139/1806\nProcessing image pair 1140/1806\nProcessing image pair 1141/1806\nProcessing image pair 1142/1806\nProcessing image pair 1143/1806\nProcessing image pair 1144/1806\nProcessing image pair 1145/1806\nProcessing image pair 1146/1806\nProcessing image pair 1147/1806\nProcessing image pair 1148/1806\nProcessing image pair 1149/1806\nProcessing image pair 1150/1806\nProcessing image pair 1151/1806\nProcessing image pair 1152/1806\nProcessing image pair 1153/1806\nProcessing image pair 1154/1806\nProcessing image pair 1155/1806\nProcessing image pair 1156/1806\nProcessing image pair 1157/1806\nProcessing image pair 1158/1806\nProcessing image pair 1159/1806\nProcessing image pair 1160/1806\nProcessing image pair 1161/1806\nProcessing image pair 1162/1806\nProcessing image pair 1163/1806\nProcessing image pair 1164/1806\nProcessing image pair 1165/1806\nProcessing image pair 1166/1806\nProcessing image pair 1167/1806\nProcessing image pair 1168/1806\nProcessing image pair 1169/1806\nProcessing image pair 1170/1806\nProcessing image pair 1171/1806\nProcessing image pair 1172/1806\nProcessing image pair 1173/1806\nProcessing image pair 1174/1806\nProcessing image pair 1175/1806\nProcessing image pair 1176/1806\nProcessing image pair 1177/1806\nProcessing image pair 1178/1806\nProcessing image pair 1179/1806\nProcessing image pair 1180/1806\nProcessing image pair 1181/1806\nProcessing image pair 1182/1806\nProcessing image pair 1183/1806\nProcessing image pair 1184/1806\nProcessing image pair 1185/1806\nProcessing image pair 1186/1806\nProcessing image pair 1187/1806\nProcessing image pair 1188/1806\nProcessing image pair 1189/1806\nProcessing image pair 1190/1806\nProcessing image pair 1191/1806\nProcessing image pair 1192/1806\nProcessing image pair 1193/1806\nProcessing image pair 1194/1806\nProcessing image pair 1195/1806\nProcessing image pair 1196/1806\nProcessing image pair 1197/1806\nProcessing image pair 1198/1806\nProcessing image pair 1199/1806\nProcessing image pair 1200/1806\nProcessing image pair 1201/1806\nProcessing image pair 1202/1806\nProcessing image pair 1203/1806\nProcessing image pair 1204/1806\nProcessing image pair 1205/1806\nProcessing image pair 1206/1806\nProcessing image pair 1207/1806\nProcessing image pair 1208/1806\nProcessing image pair 1209/1806\nProcessing image pair 1210/1806\nProcessing image pair 1211/1806\nProcessing image pair 1212/1806\nProcessing image pair 1213/1806\nProcessing image pair 1214/1806\nProcessing image pair 1215/1806\nProcessing image pair 1216/1806\nProcessing image pair 1217/1806\nProcessing image pair 1218/1806\nProcessing image pair 1219/1806\nProcessing image pair 1220/1806\nProcessing image pair 1221/1806\nProcessing image pair 1222/1806\nProcessing image pair 1223/1806\nProcessing image pair 1224/1806\nProcessing image pair 1225/1806\nProcessing image pair 1226/1806\nProcessing image pair 1227/1806\nProcessing image pair 1228/1806\nProcessing image pair 1229/1806\nProcessing image pair 1230/1806\nProcessing image pair 1231/1806\nProcessing image pair 1232/1806\nProcessing image pair 1233/1806\nProcessing image pair 1234/1806\nProcessing image pair 1235/1806\nProcessing image pair 1236/1806\nProcessing image pair 1237/1806\nProcessing image pair 1238/1806\nProcessing image pair 1239/1806\nProcessing image pair 1240/1806\nProcessing image pair 1241/1806\nProcessing image pair 1242/1806\nProcessing image pair 1243/1806\nProcessing image pair 1244/1806\nProcessing image pair 1245/1806\nProcessing image pair 1246/1806\nProcessing image pair 1247/1806\nProcessing image pair 1248/1806\nProcessing image pair 1249/1806\nProcessing image pair 1250/1806\nProcessing image pair 1251/1806\nProcessing image pair 1252/1806\nProcessing image pair 1253/1806\nProcessing image pair 1254/1806\nProcessing image pair 1255/1806\nProcessing image pair 1256/1806\nProcessing image pair 1257/1806\nProcessing image pair 1258/1806\nProcessing image pair 1259/1806\nProcessing image pair 1260/1806\nProcessing image pair 1261/1806\nProcessing image pair 1262/1806\nProcessing image pair 1263/1806\nProcessing image pair 1264/1806\nProcessing image pair 1265/1806\nProcessing image pair 1266/1806\nProcessing image pair 1267/1806\nProcessing image pair 1268/1806\nProcessing image pair 1269/1806\nProcessing image pair 1270/1806\nProcessing image pair 1271/1806\nProcessing image pair 1272/1806\nProcessing image pair 1273/1806\nProcessing image pair 1274/1806\nProcessing image pair 1275/1806\nProcessing image pair 1276/1806\nProcessing image pair 1277/1806\nProcessing image pair 1278/1806\nProcessing image pair 1279/1806\nProcessing image pair 1280/1806\nProcessing image pair 1281/1806\nProcessing image pair 1282/1806\nProcessing image pair 1283/1806\nProcessing image pair 1284/1806\nProcessing image pair 1285/1806\nProcessing image pair 1286/1806\nProcessing image pair 1287/1806\nProcessing image pair 1288/1806\nProcessing image pair 1289/1806\nProcessing image pair 1290/1806\nProcessing image pair 1291/1806\nProcessing image pair 1292/1806\nProcessing image pair 1293/1806\nProcessing image pair 1294/1806\nProcessing image pair 1295/1806\nProcessing image pair 1296/1806\nProcessing image pair 1297/1806\nProcessing image pair 1298/1806\nProcessing image pair 1299/1806\nProcessing image pair 1300/1806\nProcessing image pair 1301/1806\nProcessing image pair 1302/1806\nProcessing image pair 1303/1806\nProcessing image pair 1304/1806\nProcessing image pair 1305/1806\nProcessing image pair 1306/1806\nProcessing image pair 1307/1806\nProcessing image pair 1308/1806\nProcessing image pair 1309/1806\nProcessing image pair 1310/1806\nProcessing image pair 1311/1806\nProcessing image pair 1312/1806\nProcessing image pair 1313/1806\nProcessing image pair 1314/1806\nProcessing image pair 1315/1806\nProcessing image pair 1316/1806\nProcessing image pair 1317/1806\nProcessing image pair 1318/1806\nProcessing image pair 1319/1806\nProcessing image pair 1320/1806\nProcessing image pair 1321/1806\nProcessing image pair 1322/1806\nProcessing image pair 1323/1806\nProcessing image pair 1324/1806\nProcessing image pair 1325/1806\nProcessing image pair 1326/1806\nProcessing image pair 1327/1806\nProcessing image pair 1328/1806\nProcessing image pair 1329/1806\nProcessing image pair 1330/1806\nProcessing image pair 1331/1806\nProcessing image pair 1332/1806\nProcessing image pair 1333/1806\nProcessing image pair 1334/1806\nProcessing image pair 1335/1806\nProcessing image pair 1336/1806\nProcessing image pair 1337/1806\nProcessing image pair 1338/1806\nProcessing image pair 1339/1806\nProcessing image pair 1340/1806\nProcessing image pair 1341/1806\nProcessing image pair 1342/1806\nProcessing image pair 1343/1806\nProcessing image pair 1344/1806\nProcessing image pair 1345/1806\nProcessing image pair 1346/1806\nProcessing image pair 1347/1806\nProcessing image pair 1348/1806\nProcessing image pair 1349/1806\nProcessing image pair 1350/1806\nProcessing image pair 1351/1806\nProcessing image pair 1352/1806\nProcessing image pair 1353/1806\nProcessing image pair 1354/1806\nProcessing image pair 1355/1806\nProcessing image pair 1356/1806\nProcessing image pair 1357/1806\nProcessing image pair 1358/1806\nProcessing image pair 1359/1806\nProcessing image pair 1360/1806\nProcessing image pair 1361/1806\nProcessing image pair 1362/1806\nProcessing image pair 1363/1806\nProcessing image pair 1364/1806\nProcessing image pair 1365/1806\nProcessing image pair 1366/1806\nProcessing image pair 1367/1806\nProcessing image pair 1368/1806\nProcessing image pair 1369/1806\nProcessing image pair 1370/1806\nProcessing image pair 1371/1806\nProcessing image pair 1372/1806\nProcessing image pair 1373/1806\nProcessing image pair 1374/1806\nProcessing image pair 1375/1806\nProcessing image pair 1376/1806\nProcessing image pair 1377/1806\nProcessing image pair 1378/1806\nProcessing image pair 1379/1806\nProcessing image pair 1380/1806\nProcessing image pair 1381/1806\nProcessing image pair 1382/1806\nProcessing image pair 1383/1806\nProcessing image pair 1384/1806\nProcessing image pair 1385/1806\nProcessing image pair 1386/1806\nProcessing image pair 1387/1806\nProcessing image pair 1388/1806\nProcessing image pair 1389/1806\nProcessing image pair 1390/1806\nProcessing image pair 1391/1806\nProcessing image pair 1392/1806\nProcessing image pair 1393/1806\nProcessing image pair 1394/1806\nProcessing image pair 1395/1806\nProcessing image pair 1396/1806\nProcessing image pair 1397/1806\nProcessing image pair 1398/1806\nProcessing image pair 1399/1806\nProcessing image pair 1400/1806\nProcessing image pair 1401/1806\nProcessing image pair 1402/1806\nProcessing image pair 1403/1806\nProcessing image pair 1404/1806\nProcessing image pair 1405/1806\nProcessing image pair 1406/1806\nProcessing image pair 1407/1806\nProcessing image pair 1408/1806\nProcessing image pair 1409/1806\nProcessing image pair 1410/1806\nProcessing image pair 1411/1806\nProcessing image pair 1412/1806\nProcessing image pair 1413/1806\nProcessing image pair 1414/1806\nProcessing image pair 1415/1806\nProcessing image pair 1416/1806\nProcessing image pair 1417/1806\nProcessing image pair 1418/1806\nProcessing image pair 1419/1806\nProcessing image pair 1420/1806\nProcessing image pair 1421/1806\nProcessing image pair 1422/1806\nProcessing image pair 1423/1806\nProcessing image pair 1424/1806\nProcessing image pair 1425/1806\nProcessing image pair 1426/1806\nProcessing image pair 1427/1806\nProcessing image pair 1428/1806\nProcessing image pair 1429/1806\nProcessing image pair 1430/1806\nProcessing image pair 1431/1806\nProcessing image pair 1432/1806\nProcessing image pair 1433/1806\nProcessing image pair 1434/1806\nProcessing image pair 1435/1806\nProcessing image pair 1436/1806\nProcessing image pair 1437/1806\nProcessing image pair 1438/1806\nProcessing image pair 1439/1806\nProcessing image pair 1440/1806\nProcessing image pair 1441/1806\nProcessing image pair 1442/1806\nProcessing image pair 1443/1806\nProcessing image pair 1444/1806\nProcessing image pair 1445/1806\nProcessing image pair 1446/1806\nProcessing image pair 1447/1806\nProcessing image pair 1448/1806\nProcessing image pair 1449/1806\nProcessing image pair 1450/1806\nProcessing image pair 1451/1806\nProcessing image pair 1452/1806\nProcessing image pair 1453/1806\nProcessing image pair 1454/1806\nProcessing image pair 1455/1806\nProcessing image pair 1456/1806\nProcessing image pair 1457/1806\nProcessing image pair 1458/1806\nProcessing image pair 1459/1806\nProcessing image pair 1460/1806\nProcessing image pair 1461/1806\nProcessing image pair 1462/1806\nProcessing image pair 1463/1806\nProcessing image pair 1464/1806\nProcessing image pair 1465/1806\nProcessing image pair 1466/1806\nProcessing image pair 1467/1806\nProcessing image pair 1468/1806\nProcessing image pair 1469/1806\nProcessing image pair 1470/1806\nProcessing image pair 1471/1806\nProcessing image pair 1472/1806\nProcessing image pair 1473/1806\nProcessing image pair 1474/1806\nProcessing image pair 1475/1806\nProcessing image pair 1476/1806\nProcessing image pair 1477/1806\nProcessing image pair 1478/1806\nProcessing image pair 1479/1806\nProcessing image pair 1480/1806\nProcessing image pair 1481/1806\nProcessing image pair 1482/1806\nProcessing image pair 1483/1806\nProcessing image pair 1484/1806\nProcessing image pair 1485/1806\nProcessing image pair 1486/1806\nProcessing image pair 1487/1806\nProcessing image pair 1488/1806\nProcessing image pair 1489/1806\nProcessing image pair 1490/1806\nProcessing image pair 1491/1806\nProcessing image pair 1492/1806\nProcessing image pair 1493/1806\nProcessing image pair 1494/1806\nProcessing image pair 1495/1806\nProcessing image pair 1496/1806\nProcessing image pair 1497/1806\nProcessing image pair 1498/1806\nProcessing image pair 1499/1806\nProcessing image pair 1500/1806\nProcessing image pair 1501/1806\nProcessing image pair 1502/1806\nProcessing image pair 1503/1806\nProcessing image pair 1504/1806\nProcessing image pair 1505/1806\nProcessing image pair 1506/1806\nProcessing image pair 1507/1806\nProcessing image pair 1508/1806\nProcessing image pair 1509/1806\nProcessing image pair 1510/1806\nProcessing image pair 1511/1806\nProcessing image pair 1512/1806\nProcessing image pair 1513/1806\nProcessing image pair 1514/1806\nProcessing image pair 1515/1806\nProcessing image pair 1516/1806\nProcessing image pair 1517/1806\nProcessing image pair 1518/1806\nProcessing image pair 1519/1806\nProcessing image pair 1520/1806\nProcessing image pair 1521/1806\nProcessing image pair 1522/1806\nProcessing image pair 1523/1806\nProcessing image pair 1524/1806\nProcessing image pair 1525/1806\nProcessing image pair 1526/1806\nProcessing image pair 1527/1806\nProcessing image pair 1528/1806\nProcessing image pair 1529/1806\nProcessing image pair 1530/1806\nProcessing image pair 1531/1806\nProcessing image pair 1532/1806\nProcessing image pair 1533/1806\nProcessing image pair 1534/1806\nProcessing image pair 1535/1806\nProcessing image pair 1536/1806\nProcessing image pair 1537/1806\nProcessing image pair 1538/1806\nProcessing image pair 1539/1806\nProcessing image pair 1540/1806\nProcessing image pair 1541/1806\nProcessing image pair 1542/1806\nProcessing image pair 1543/1806\nProcessing image pair 1544/1806\nProcessing image pair 1545/1806\nProcessing image pair 1546/1806\nProcessing image pair 1547/1806\nProcessing image pair 1548/1806\nProcessing image pair 1549/1806\nProcessing image pair 1550/1806\nProcessing image pair 1551/1806\nProcessing image pair 1552/1806\nProcessing image pair 1553/1806\nProcessing image pair 1554/1806\nProcessing image pair 1555/1806\nProcessing image pair 1556/1806\nProcessing image pair 1557/1806\nProcessing image pair 1558/1806\nProcessing image pair 1559/1806\nProcessing image pair 1560/1806\nProcessing image pair 1561/1806\nProcessing image pair 1562/1806\nProcessing image pair 1563/1806\nProcessing image pair 1564/1806\nProcessing image pair 1565/1806\nProcessing image pair 1566/1806\nProcessing image pair 1567/1806\nProcessing image pair 1568/1806\nProcessing image pair 1569/1806\nProcessing image pair 1570/1806\nProcessing image pair 1571/1806\nProcessing image pair 1572/1806\nProcessing image pair 1573/1806\nProcessing image pair 1574/1806\nProcessing image pair 1575/1806\nProcessing image pair 1576/1806\nProcessing image pair 1577/1806\nProcessing image pair 1578/1806\nProcessing image pair 1579/1806\nProcessing image pair 1580/1806\nProcessing image pair 1581/1806\nProcessing image pair 1582/1806\nProcessing image pair 1583/1806\nProcessing image pair 1584/1806\nProcessing image pair 1585/1806\nProcessing image pair 1586/1806\nProcessing image pair 1587/1806\nProcessing image pair 1588/1806\nProcessing image pair 1589/1806\nProcessing image pair 1590/1806\nProcessing image pair 1591/1806\nProcessing image pair 1592/1806\nProcessing image pair 1593/1806\nProcessing image pair 1594/1806\nProcessing image pair 1595/1806\nProcessing image pair 1596/1806\nProcessing image pair 1597/1806\nProcessing image pair 1598/1806\nProcessing image pair 1599/1806\nProcessing image pair 1600/1806\nProcessing image pair 1601/1806\nProcessing image pair 1602/1806\nProcessing image pair 1603/1806\nProcessing image pair 1604/1806\nProcessing image pair 1605/1806\nProcessing image pair 1606/1806\nProcessing image pair 1607/1806\nProcessing image pair 1608/1806\nProcessing image pair 1609/1806\nProcessing image pair 1610/1806\nProcessing image pair 1611/1806\nProcessing image pair 1612/1806\nProcessing image pair 1613/1806\nProcessing image pair 1614/1806\nProcessing image pair 1615/1806\nProcessing image pair 1616/1806\nProcessing image pair 1617/1806\nProcessing image pair 1618/1806\nProcessing image pair 1619/1806\nProcessing image pair 1620/1806\nProcessing image pair 1621/1806\nProcessing image pair 1622/1806\nProcessing image pair 1623/1806\nProcessing image pair 1624/1806\nProcessing image pair 1625/1806\nProcessing image pair 1626/1806\nProcessing image pair 1627/1806\nProcessing image pair 1628/1806\nProcessing image pair 1629/1806\nProcessing image pair 1630/1806\nProcessing image pair 1631/1806\nProcessing image pair 1632/1806\nProcessing image pair 1633/1806\nProcessing image pair 1634/1806\nProcessing image pair 1635/1806\nProcessing image pair 1636/1806\nProcessing image pair 1637/1806\nProcessing image pair 1638/1806\nProcessing image pair 1639/1806\nProcessing image pair 1640/1806\nProcessing image pair 1641/1806\nProcessing image pair 1642/1806\nProcessing image pair 1643/1806\nProcessing image pair 1644/1806\nProcessing image pair 1645/1806\nProcessing image pair 1646/1806\nProcessing image pair 1647/1806\nProcessing image pair 1648/1806\nProcessing image pair 1649/1806\nProcessing image pair 1650/1806\nProcessing image pair 1651/1806\nProcessing image pair 1652/1806\nProcessing image pair 1653/1806\nProcessing image pair 1654/1806\nProcessing image pair 1655/1806\nProcessing image pair 1656/1806\nProcessing image pair 1657/1806\nProcessing image pair 1658/1806\nProcessing image pair 1659/1806\nProcessing image pair 1660/1806\nProcessing image pair 1661/1806\nProcessing image pair 1662/1806\nProcessing image pair 1663/1806\nProcessing image pair 1664/1806\nProcessing image pair 1665/1806\nProcessing image pair 1666/1806\nProcessing image pair 1667/1806\nProcessing image pair 1668/1806\nProcessing image pair 1669/1806\nProcessing image pair 1670/1806\nProcessing image pair 1671/1806\nProcessing image pair 1672/1806\nProcessing image pair 1673/1806\nProcessing image pair 1674/1806\nProcessing image pair 1675/1806\nProcessing image pair 1676/1806\nProcessing image pair 1677/1806\nProcessing image pair 1678/1806\nProcessing image pair 1679/1806\nProcessing image pair 1680/1806\nProcessing image pair 1681/1806\nProcessing image pair 1682/1806\nProcessing image pair 1683/1806\nProcessing image pair 1684/1806\nProcessing image pair 1685/1806\nProcessing image pair 1686/1806\nProcessing image pair 1687/1806\nProcessing image pair 1688/1806\nProcessing image pair 1689/1806\nProcessing image pair 1690/1806\nProcessing image pair 1691/1806\nProcessing image pair 1692/1806\nProcessing image pair 1693/1806\nProcessing image pair 1694/1806\nProcessing image pair 1695/1806\nProcessing image pair 1696/1806\nProcessing image pair 1697/1806\nProcessing image pair 1698/1806\nProcessing image pair 1699/1806\nProcessing image pair 1700/1806\nProcessing image pair 1701/1806\nProcessing image pair 1702/1806\nProcessing image pair 1703/1806\nProcessing image pair 1704/1806\nProcessing image pair 1705/1806\nProcessing image pair 1706/1806\nProcessing image pair 1707/1806\nProcessing image pair 1708/1806\nProcessing image pair 1709/1806\nProcessing image pair 1710/1806\nProcessing image pair 1711/1806\nProcessing image pair 1712/1806\nProcessing image pair 1713/1806\nProcessing image pair 1714/1806\nProcessing image pair 1715/1806\nProcessing image pair 1716/1806\nProcessing image pair 1717/1806\nProcessing image pair 1718/1806\nProcessing image pair 1719/1806\nProcessing image pair 1720/1806\nProcessing image pair 1721/1806\nProcessing image pair 1722/1806\nProcessing image pair 1723/1806\nProcessing image pair 1724/1806\nProcessing image pair 1725/1806\nProcessing image pair 1726/1806\nProcessing image pair 1727/1806\nProcessing image pair 1728/1806\nProcessing image pair 1729/1806\nProcessing image pair 1730/1806\nProcessing image pair 1731/1806\nProcessing image pair 1732/1806\nProcessing image pair 1733/1806\nProcessing image pair 1734/1806\nProcessing image pair 1735/1806\nProcessing image pair 1736/1806\nProcessing image pair 1737/1806\nProcessing image pair 1738/1806\nProcessing image pair 1739/1806\nProcessing image pair 1740/1806\nProcessing image pair 1741/1806\nProcessing image pair 1742/1806\nProcessing image pair 1743/1806\nProcessing image pair 1744/1806\nProcessing image pair 1745/1806\nProcessing image pair 1746/1806\nProcessing image pair 1747/1806\nProcessing image pair 1748/1806\nProcessing image pair 1749/1806\nProcessing image pair 1750/1806\nProcessing image pair 1751/1806\nProcessing image pair 1752/1806\nProcessing image pair 1753/1806\nProcessing image pair 1754/1806\nProcessing image pair 1755/1806\nProcessing image pair 1756/1806\nProcessing image pair 1757/1806\nProcessing image pair 1758/1806\nProcessing image pair 1759/1806\nProcessing image pair 1760/1806\nProcessing image pair 1761/1806\nProcessing image pair 1762/1806\nProcessing image pair 1763/1806\nProcessing image pair 1764/1806\nProcessing image pair 1765/1806\nProcessing image pair 1766/1806\nProcessing image pair 1767/1806\nProcessing image pair 1768/1806\nProcessing image pair 1769/1806\nProcessing image pair 1770/1806\nProcessing image pair 1771/1806\nProcessing image pair 1772/1806\nProcessing image pair 1773/1806\nProcessing image pair 1774/1806\nProcessing image pair 1775/1806\nProcessing image pair 1776/1806\nProcessing image pair 1777/1806\nProcessing image pair 1778/1806\nProcessing image pair 1779/1806\nProcessing image pair 1780/1806\nProcessing image pair 1781/1806\nProcessing image pair 1782/1806\nProcessing image pair 1783/1806\nProcessing image pair 1784/1806\nProcessing image pair 1785/1806\nProcessing image pair 1786/1806\nProcessing image pair 1787/1806\nProcessing image pair 1788/1806\nProcessing image pair 1789/1806\nProcessing image pair 1790/1806\nProcessing image pair 1791/1806\nProcessing image pair 1792/1806\nProcessing image pair 1793/1806\nProcessing image pair 1794/1806\nProcessing image pair 1795/1806\nProcessing image pair 1796/1806\nProcessing image pair 1797/1806\nProcessing image pair 1798/1806\nProcessing image pair 1799/1806\nProcessing image pair 1800/1806\nProcessing image pair 1801/1806\nProcessing image pair 1802/1806\nProcessing image pair 1803/1806\nProcessing image pair 1804/1806\nProcessing image pair 1805/1806\nProcessing image pair 1806/1806\nAverage SSIM: 0.8484\nAverage PSNR: 23.6283 dB\nAverage MSE: 0.0066\nAverage UIQM: 2.8523\nAverage UCIQE: 0.5134\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torchvision\nfrom torchvision import transforms\nimport time\nfrom tqdm import tqdm\nimport os\nimport torch\nimport torch.nn as nn\nfrom torchvision.utils import save_image\nfrom glob import glob\nfrom PIL import Image\nfrom os.path import join\nfrom scipy import ndimage\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom scipy.ndimage import gaussian_filter  # **Import gaussian_filter**\nimport math\n\n# Ensure environment variable for Kaggle\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n\nclass UIEDataset(Dataset):\n    def __init__(self, raw_dir, reference_dir, transform=None):\n        self.raw_dir = raw_dir\n        self.reference_dir = reference_dir\n        self.transform = transform\n        self.image_names = [img for img in os.listdir(raw_dir) if img in os.listdir(reference_dir)]\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        raw_image_path = os.path.join(self.raw_dir, self.image_names[idx])\n        reference_image_path = os.path.join(self.reference_dir, self.image_names[idx])\n\n        raw_image = Image.open(raw_image_path).convert(\"RGB\")\n        reference_image = Image.open(reference_image_path).convert(\"RGB\")\n\n        if self.transform:\n            raw_image = self.transform(raw_image)\n            reference_image = self.transform(reference_image)\n\n        return raw_image, reference_image\n\n# SSIM and PSNR Calculation\ndef getSSIM(X, Y):\n    assert (X.shape == Y.shape), \"Image patches provided have different dimensions\"\n    nch = 1 if X.ndim == 2 else X.shape[-1]\n    mssim = []\n    for ch in range(nch):\n        Xc, Yc = X[..., ch].astype(np.float64), Y[..., ch].astype(np.float64)\n        mssim.append(compute_ssim(Xc, Yc))  # **Updated call to compute_ssim**\n    return np.mean(mssim)\n\ndef compute_ssim(X, Y):\n    K1 = 0.01\n    K2 = 0.03\n    sigma = 1.5\n    win_size = 5\n\n    ux = gaussian_filter(X, sigma)  # **Update for SSIM calculation**\n    uy = gaussian_filter(Y, sigma)  # **Update for SSIM calculation**\n\n    uxx = gaussian_filter(X * X, sigma)\n    uyy = gaussian_filter(Y * Y, sigma)\n    uxy = gaussian_filter(X * Y, sigma)\n\n    N = win_size ** X.ndim\n    unbiased_norm = N / (N - 1)\n    vx = (uxx - ux * ux) * unbiased_norm\n    vy = (uyy - uy * uy) * unbiased_norm\n    vxy = (uxy - ux * uy) * unbiased_norm\n\n    R = 255\n    C1 = (K1 * R) ** 2\n    C2 = (K2 * R) ** 2\n    sim = (2 * ux * uy + C1) * (2 * vxy + C2)\n    D = (ux ** 2 + uy ** 2 + C1) * (vx + vy + C2)\n    SSIM = sim / D\n    mssim = SSIM.mean()\n\n    return mssim\n\ndef getPSNR(X, Y):\n    target_data = np.array(X, dtype=np.float64)\n    ref_data = np.array(Y, dtype=np.float64)\n    diff = ref_data - target_data\n    diff = diff.flatten('C')\n    rmse = math.sqrt(np.mean(diff ** 2.))\n    if rmse == 0: return 100\n    else: return 20 * math.log10(255.0 / rmse)\n\n\n# UIQM Calculation\ndef mu_a(x, alpha_L=0.1, alpha_R=0.1):\n    x = sorted(x)\n    K = len(x)\n    T_a_L = math.ceil(alpha_L * K)\n    T_a_R = math.floor(alpha_R * K)\n    weight = (1 / (K - T_a_L - T_a_R))\n    s = int(T_a_L + 1)\n    e = int(K - T_a_R)\n    val = sum(x[s:e])\n    return weight * val\n\ndef s_a(x, mu):\n    return sum(math.pow((pixel - mu), 2) for pixel in x) / len(x)\n\ndef _uicm(x):\n    R = x[:, :, 0].flatten()\n    G = x[:, :, 1].flatten()\n    B = x[:, :, 2].flatten()\n    RG = R - G\n    YB = ((R + G) / 2) - B\n    mu_a_RG = mu_a(RG)\n    mu_a_YB = mu_a(YB)\n    s_a_RG = s_a(RG, mu_a_RG)\n    s_a_YB = s_a(YB, mu_a_YB)\n    l = math.sqrt(math.pow(mu_a_RG, 2) + math.pow(mu_a_YB, 2))\n    r = math.sqrt(s_a_RG + s_a_YB)\n    return (-0.0268 * l) + (0.1586 * r)\n\ndef sobel(x):\n    dx = ndimage.sobel(x, 0)\n    dy = ndimage.sobel(x, 1)\n    mag = np.hypot(dx, dy)\n    mag *= 255.0 / np.max(mag)\n    return mag\n\ndef eme(x, window_size):\n    k1 = int(x.shape[1] / window_size)\n    k2 = int(x.shape[0] / window_size)\n    w = 2. / (k1 * k2)\n    x = x[:window_size * k2, :window_size * k1]\n    val = 0\n    for l in range(k1):\n        for k in range(k2):\n            block = x[k * window_size:window_size * (k + 1), l * window_size:window_size * (l + 1)]\n            max_ = np.max(block)\n            min_ = np.min(block)\n            if min_ == 0.0 or max_ == 0.0: \n                val += 0\n            else:\n                val += math.log(max_ / min_)\n    return w * val\n\ndef _uism(x):\n    R = x[:, :, 0]\n    G = x[:, :, 1]\n    B = x[:, :, 2]\n    Rs = sobel(R)\n    Gs = sobel(G)\n    Bs = sobel(B)\n    R_edge_map = np.multiply(Rs, R)\n    G_edge_map = np.multiply(Gs, G)\n    B_edge_map = np.multiply(Bs, B)\n    r_eme = eme(R_edge_map, 10)\n    g_eme = eme(G_edge_map, 10)\n    b_eme = eme(B_edge_map, 10)\n    lambda_r = 0.299\n    lambda_g = 0.587\n    lambda_b = 0.144\n    return (lambda_r * r_eme) + (lambda_g * g_eme) + (lambda_b * b_eme)\n\ndef plip_g(x, mu=1026.0):\n    return mu - x\n\ndef plip_theta(g1, g2, k):\n    g1 = plip_g(g1)\n    g2 = plip_g(g2)\n    return k * ((g1 - g2) / (k - g2))\n\ndef plip_cross(g1, g2, gamma):\n    g1 = plip_g(g1)\n    g2 = plip_g(g2)\n    return g1 + g2 - ((g1 * g2) / gamma)\n\ndef plip_diag(c, g, gamma):\n    g = plip_g(g)\n    return gamma - (gamma * math.pow((1 - (g / gamma)), c))\n\ndef plip_multiplication(g1, g2):\n    return plip_phiInverse(plip_phi(g1) * plip_phi(g2))\n\ndef plip_phiInverse(g):\n    plip_lambda = 1026.0\n    plip_beta = 1.0\n    return plip_lambda * (1 - math.pow(math.exp(-g / plip_lambda), 1 / plip_beta))\n\ndef plip_phi(g):\n    plip_lambda = 1026.0\n    plip_beta = 1.0\n    return -plip_lambda * math.pow(math.log(1 - g / plip_lambda), plip_beta)\n\ndef _uiconm(x, window_size):\n    plip_lambda = 1026.0\n    plip_gamma = 1026.0\n    plip_beta = 1.0\n    plip_mu = 1026.0\n    plip_k = 1026.0\n    k1 = int(x.shape[1] / window_size)\n    k2 = int(x.shape[0] / window_size)\n    w = -1. / (k1 * k2)\n    x = x[:window_size * k2, :window_size * k1]\n    alpha = 1\n    val = 0\n    for l in range(k1):\n        for k in range(k2):\n            block = x[k * window_size:window_size * (k + 1), l * window_size:window_size * (l + 1), :]\n            max_ = np.max(block)\n            min_ = np.min(block)\n            top = max_ - min_\n            bot = max_ + min_\n            if math.isnan(top) or math.isnan(bot) or bot == 0.0 or top == 0.0:\n                val += 0.0\n            else:\n                val += alpha * math.pow((top / bot), alpha) * math.log(top / bot)\n    return w * val\n\ndef getUIQM(x):\n    x = x.astype(np.float32)\n    c1 = 0.0282\n    c2 = 0.2953\n    c3 = 3.5753\n    uicm = _uicm(x)\n    uism = _uism(x)\n    uiconm = _uiconm(x, 10)\n    return (c1 * uicm) + (c2 * uism) + (c3 * uiconm)\n\ndef test(config, test_dataloader, test_model):\n    with torch.no_grad():\n        for i, (input, target) in enumerate(test_dataloader):\n            input = input.to(config['device'])\n            output = test_model(input)\n            \n            for j in range(output.size(0)):\n                # Assuming name[j] is part of the test_dataloader output and is a string filename\n                name = test_dataloader.dataset.image_names[i * config['batch_size'] + j]  # Get the image name\n\n                output_image = output[j].cpu().clamp(0, 1)  # Clamp the output to the range [0, 1]\n                output_image = transforms.ToPILImage()(output_image)\n\n                output_path = os.path.join(config['output_images_path'], name)  # Combine the output path and image name\n                output_image.save(output_path)\n\n    print(\"Testing completed.\")\n\n\n\ndef setup(config):\n    if torch.cuda.is_available():\n        config['device'] = \"cuda\"\n    else:\n        config['device'] = \"cpu\"\n\n    # Load the entire model\n    model = torch.load(config['snapshot_path'], map_location=config['device'])\n    model.to(config['device'])\n    model.eval()\n\n    transform = transforms.Compose([\n        transforms.Resize((config['resize'], config['resize'])),\n        transforms.ToTensor()\n    ])\n    \n    # Ensure both raw and reference directories are passed\n    test_dataset = UIEDataset(config['test_images_path'], config['label_images_path'], transform)\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n    \n    print(\"Test Dataset Reading Completed.\")\n    return test_dataloader, model\n\n\n\ndef SSIMs_PSNRs(gtr_dir, gen_dir, im_res=(256, 256)):\n    gtr_paths = sorted(glob(join(gtr_dir, \"*.*\")))\n    gen_paths = sorted(glob(join(gen_dir, \"*.*\")))\n    ssims, psnrs = [], []\n    \n    for gtr_path, gen_path in zip(gtr_paths, gen_paths):\n        r_im = Image.open(gtr_path).resize(im_res)\n        g_im = Image.open(gen_path).resize(im_res)\n        \n        # SSIM calculation\n        ssim = getSSIM(np.array(r_im), np.array(g_im))\n        ssims.append(ssim)\n        \n        # PSNR calculation\n        r_im = r_im.convert(\"L\")\n        g_im = g_im.convert(\"L\")\n        psnr = getPSNR(np.array(r_im), np.array(g_im))\n        psnrs.append(psnr)\n        \n    # Calculate averages and standard deviations\n    avg_ssim = np.mean(ssims)\n    avg_psnr = np.mean(psnrs)\n    std_ssim = np.std(ssims)\n    std_psnr = np.std(psnrs)\n    \n    return avg_ssim, avg_psnr, std_ssim, std_psnr\n\ndef measure_UIQMs(dir_name, im_res=(256, 256)):\n    paths = sorted(glob(join(dir_name, \"*.*\")))\n    uqims = []\n    \n    for img_path in paths:\n        im = Image.open(img_path).resize(im_res)\n        uiqm = getUIQM(np.array(im))\n        uqims.append(uiqm)\n    \n    # Calculate averages and standard deviations\n    avg_uiqm = np.mean(uqims)\n    std_uiqm = np.std(uqims)\n    \n    return avg_uiqm, std_uiqm\n\n# Kaggle specific setup\nif __name__ == '__main__':\n    config = {\n        'snapshot_path': \"/kaggle/input/data2-finalmodels/final_model.pt\",\n        'test_images_path': \"/kaggle/input/imgenh-2/dataset-2/Test/Raw\",\n        'output_images_path': \"/kaggle/working/Gen-output-1\",\n        'batch_size': 1,\n        'resize': 256,\n        'calculate_metrics': True,\n        'label_images_path': \"/kaggle/input/imgenh-2/dataset-2/Test/Reference\"\n    }\n\n    if not os.path.exists(config['output_images_path']):\n        os.mkdir(config['output_images_path'])\n\n    start_time = time.time()\n    ds_test, model = setup(config)\n    test(config, ds_test, model)\n    print(\"Total testing time:\", time.time() - start_time)\n\n    # Calculate metrics if specified\n    if config['calculate_metrics']:\n        gen_uqims, _ = measure_UIQMs(config['output_images_path'])\n        avg_uiqm, _ = measure_UIQMs(config['output_images_path'])\n\n        avg_ssim, avg_psnr, _, _ = SSIMs_PSNRs(config['label_images_path'], config['output_images_path'])\n        print(f\"Average SSIM: {avg_ssim:.4f}\")\n        print(f\"Average PSNR: {avg_psnr:.4f} dB\")\n        print(f\"Average UIQM: {avg_uiqm:.4f}\")\n        \n\n      \n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T07:45:42.094906Z","iopub.execute_input":"2024-09-16T07:45:42.095303Z","iopub.status.idle":"2024-09-16T08:05:19.957152Z","shell.execute_reply.started":"2024-09-16T07:45:42.095251Z","shell.execute_reply":"2024-09-16T08:05:19.956189Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Test Dataset Reading Completed.\nTesting completed.\nTotal testing time: 121.78503847122192\nAverage SSIM: 0.8603\nAverage PSNR: 29.5985 dB\nAverage UIQM: 3.0313\n","output_type":"stream"}]}]}